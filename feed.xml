<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://zblasingame.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://zblasingame.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-04T01:01:24+00:00</updated><id>https://zblasingame.github.io/feed.xml</id><title type="html">blank</title><subtitle>My webpage. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Gradients for Time Scheduled Conditional Variables in Neural Differential Equations</title><link href="https://zblasingame.github.io/blog/2024/cadlag-conditional/" rel="alternate" type="text/html" title="Gradients for Time Scheduled Conditional Variables in Neural Differential Equations"/><published>2024-12-03T00:00:00+00:00</published><updated>2024-12-03T00:00:00+00:00</updated><id>https://zblasingame.github.io/blog/2024/cadlag-conditional</id><content type="html" xml:base="https://zblasingame.github.io/blog/2024/cadlag-conditional/"><![CDATA[<div style="display:none"> $$ \newcommand{\R}{\mathbb{R}} \newcommand{\X}{\mathcal{X}} \newcommand{\Y}{\mathcal{Y}} \newcommand{\B}{\mathcal{B}} \newcommand{\T}{\mathbb{T}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathcal{Z}} \newcommand{\Q}{\mathbb{Q}} \newcommand{\pr}{\mathbb{P}} \newcommand{\bfx}{\mathbf{x}} \newcommand{\bfy}{\mathbf{y}} \newcommand{\bfz}{\mathbf{z}} \newcommand{\bfa}{\mathbf{a}} \newcommand{\bfw}{\mathbf{w}} \newcommand{\bfA}{\mathbf{A}} \newcommand{\bfV}{\mathbf{V}} \newcommand{\bsf}{\boldsymbol{f}} \newcommand{\bsg}{\boldsymbol{g}} \newcommand{\bseps}{\boldsymbol{\epsilon}} \newcommand{\rmd}{\mathrm{d}} \DeclareMathOperator{\var}{Var} \DeclareMathOperator{\ex}{\mathbb{E}} \DeclareMathOperator{\argmax}{arg\,max} \DeclareMathOperator{\argmin}{arg\,min} \newtheorem{proposition}{Proposition} $$ </div> <h2 id="introduction">Introduction</h2> <p>The advent of large-scale diffusion models conditioned on text embeddings<d-cite key="ldm,2022arXiv220406125R,NEURIPS2022_ec795aea"></d-cite> has allowed for creative control over the generative process. A recent and powerful technique is that of <em>prompt scheduling</em>, <em>i.e.,</em> instead of passing a fixed prompt to the diffusion model, the prompt can changed depending on the timestep. This concept was initially proposed by Doggettx <a href="https://www.reddit.com/r/StableDiffusion/comments/xas2os/simple_prompt2prompt_implementation_with_prompt/">in this reddit post</a> and the code changes to the stable diffusion repository can be seen <a href="https://github.com/CompVis/stable-diffusion/commit/ccb17b55f2e7acbd1a112b55fb8f8415b4862521">here</a>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/scheduled_conditionals/prompt_scheduling_example-480.webp 480w,/assets/img/scheduled_conditionals/prompt_scheduling_example-800.webp 800w,/assets/img/scheduled_conditionals/prompt_scheduling_example-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/scheduled_conditionals/prompt_scheduling_example.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Examples of the prompt scheduling technique proposed by Doggettx. </div> <p>More technically, assume we have a U-Net trained on the noise-prediction task \(\bseps_\theta(\bfx_t, \bfz, t)\) conditioned on a time scheduled text embedding \(\bfz(t)\). The sampling procedure amounts to solving the <em>probability flow ODE</em> from time \(T\) to time \(0\). \(\begin{equation} \frac{\rmd \bfx_t}{\rmd t} = f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t}\bseps_\theta(\bfx_t, \bfz(t), t), \end{equation}\) where $f, g$ define the drift and diffusion coefficients of a Variance Preserving (VP) type SDE <d-cite key="song2021denoising"></d-cite>.</p> <p>An active area of research in diffusion models has been the development of techniques which search of the optimal generation parameters. More specifically, they attempt to solve the following optimization problem: \(\begin{equation} \label{eq:problem_stmt_ode} \argmin_{\bfx_T, \bfz, \theta}\quad \mathcal{L}\bigg(\bfx_T + \int_T^0 f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t}\bseps_\theta(\bfx_t, \bfz, t)\;\rmd t\bigg). \end{equation}\) Several recent works this year <d-cite key="pan2024adjointdpm,adjointdeis,marion2024implicit"></d-cite> explore solving the continuous adjoint equations <d-cite key="neural_ode,adjoint_sensitivity_method,kidger_thesis"></d-cite> to find the gradients: \(\begin{equation} \frac{\partial \mathcal L}{\partial \bfx_t}, \qquad \frac{\partial \mathcal L}{\partial \bfz}, \qquad \frac{\partial \mathcal L}{\partial \theta}. \end{equation}\)</p> <p>However, what if \(\bfz\) is scheduled and not constant w.r.t to time? <em>I.e.</em>, how do we find \(\partial \mathcal L / \partial \bfz(t)\) for all \(t \in [0, T]\)? In this blog post we present one the of results from our recent NeurIPS paper <d-cite key="adjointdeis"></d-cite> which shows how to calculate this gradient.</p> <h2 id="gradients-of-time-scheduled-conditional-variables">Gradients of time-scheduled conditional variables</h2> <p>It is well known that diffusion models are just a special type of neural differential equation, either a neural ODE or SDE. We will show the result more generally for neural ODEs.</p> <blockquote> <p>The main result is that we can just <strong>simply</strong> replace \(\bfz\) with \(\bfz(t)\) in the continuous adjoint equations.</p> </blockquote> <p>This result will intuitive, does require some technical details to show.</p> <p><strong>Theorem</strong> (Continuous adjoint equations for time scheduled conditional variables)<strong>.</strong> <i> Suppose there exists a function \(\bfz: [0,T] \to \R^z\) which can be defined as a càdlàg<d-footnote>French: <i>continue a&#768; droite, limite a&#768; gauche.</i></d-footnote> piecewise function where \(\bfz\) is continuous on each partition of \([0, T]\) given by \(\Pi = \{0 = t_0 &lt; t_1 &lt; \cdots &lt; t_n = T\}\) and whose right derivatives exists for all \(t \in [0,T]\). Let \(\bsf_\theta: \R^d \times \R^z \times [0,T] \to \R^d\) be continuous in \(t\), uniformly Lipschitz in \(\bfy\), and continuously differentiable in \(\bfy\). Let \(\bfy: [0, T] \to \R^d\) be the unique solution for the ODE \(\begin{equation} \frac{\rmd \bfy}{\rmd t}(t) = \bsf_\theta(\bfy(t), \bfz(t), t), \end{equation}\) with initial condition \(\bfy(0) = \bfy_0\). Then \(\partial \mathcal L / \partial \bfz(t) := \bfa_\bfz(t)\) and there exists a unique solution \(\bfa_\bfz: [0, T] \to \R^z\) to the following initial value problem: \(\begin{equation} \bfa_\bfz(T) = \mathbf 0, \qquad \frac{\rmd \bfa_\bfz}{\rmd t}(t) = - \bfa_\bfy(t)^\top \frac{\partial \bsf_\theta(\bfy(t), \bfz(t), t)}{\partial \bfz(t)}. \end{equation}\) </i></p> <details><summary>Why càdlàg?</summary> <p>In practice \(\bfz(t)\) is often a discrete set \(\{\bfz_k\}_{k=1}^n\) where \(n\) corresponds to the number of discretization steps the numerical ODE solver takes. While the proof is easier for a continuously differentiable function \(\bfz(t)\) we opt for this construction for the sake of generality. We choose a càdlàg piecewise function, a relatively mild assumption, to ensure that the we can define the augmented state on each continuous interval of the piecewise function in terms of the right derivative.</p> </details> <p>In the remainder of this blog post will provide the proof of this result. Our proof technique is an extension of the one used by Patrick Kidger (Appendix C.3.1) <d-cite key="kidger_thesis"></d-cite> used to prove the existence to the solution to the continuous adjoint equations for neural ODEs.</p> <p><em>Proof.</em> Recall that \(\bfz(t)\) is a piecewise function of time with partition of the time domain \(\Pi\). Without loss of generality we consider some time interval \(\pi = [t_{m-1}, t_m]\) for some \(1 \leq m \leq n\). Consider the augmented state defined on the interval \(\pi\): \(\begin{equation} \frac{\rmd}{\rmd t} \begin{bmatrix} \bfy\\ \bfz \end{bmatrix}(t) = \bsf_{\text{aug}} = \begin{bmatrix} \bsf_\theta(\bfy_t, \bfz_t, t)\\ \overrightarrow\partial\bfz(t) \end{bmatrix}, \end{equation}\) where \(\overrightarrow\partial\bfz(t): [0,T] \to \R^z\) denotes the right derivative of \(\bfz\) at time \(t\). Let \(\bfa_\text{aug}\) denote the augmented state as \(\begin{equation} \label{eq:app:adjoint_aug} \bfa_\text{aug}(t) := \begin{bmatrix} \bfa_\bfy\\\bfa_\bfz \end{bmatrix}(t). \end{equation}\) Then the Jacobian of \(\bsf_\text{aug}\) is defined as \(\begin{equation} \label{eq:app:jacobian_aug} \frac{\partial \bsf_\text{aug}}{\partial [\bfy, \bfz]} = \begin{bmatrix} \frac{\partial \bsf_\theta(\bfy, \bfz, t)}{\partial \bfy} &amp; \frac{\partial \bsf_\theta(\bfy, \bfz, t)}{\partial \bfz}\\ \mathbf 0 &amp; \mathbf 0\\ \end{bmatrix}. \end{equation}\) As the state \(\bfz(t)\) evolves with \(\overrightarrow\partial\bfz(t)\) on the interval \([t_{m-1}, t_m]\) in the forward direction the derivative of this augmented vector field w.r.t. \(\bfz\) is clearly \(\mathbf 0\) as it only depends on time. Remark, as the bottom row of the Jacobian of \(\bsf_\text{aug}\) is all \(\mathbf 0\) and \(\bsf_\theta\) is continuous in \(t\) we can consider the evolution of \(\bfa_\text{aug}\) over the whole interval \([0,T]\) rather than just a partition of it. The evolution of the augmented adjoint state on \([0,T]\) is then given as \(\begin{equation} \frac{\rmd \bfa_\text{aug}}{\rmd t}(t) = -\begin{bmatrix} \bfa_\bfy &amp; \bfa_\bfz \end{bmatrix}(t) \frac{\partial \bsf_\text{aug}}{\partial [\bfy, \bfz]}(t). \end{equation}\) Therefore, $\bfa_\bfz(t)$ is a solution to the initial value problem: \(\begin{equation} \bfa_\bfz(T) = 0, \qquad \frac{\rmd \bfa_\bfz}{\rmd t}(t) = -\bfa_\bfy(t)^\top \frac{\partial \bsf_\theta(\bfy(t), \bfz(t), t)}{\partial \bfz(t)}. \end{equation}\)</p> <p>Next we show that there exist a unique solution to the initial value problem. Now as \(\bfy\) is continuous and \(\bsf_\theta\) is continuously differentiable in \(\bfy\) it follows that \(t \mapsto \frac{\partial \bsf_\theta}{\partial \bfy}(\bfy(t), \bfz(t), t)\) is a continuous function on the compact set \([t_{m-1}, t_m]\). As such it is bounded by some \(L &gt; 0\). Likewise, for \(\bfa_\bfy \in \R^d\) the map \((t, \bfa_\bfy) \mapsto -\bfa_\bfy \frac{\partial \bsf_\theta}{\partial [\bfy, \bfz]}(\bfy(t), \bfz(t), t)\) is Lipschitz in \(\bfa_\bfy\) with Lipschitz constant \(L\) and this constant is independent of \(t\). Therefore, by the <a href="https://en.wikipedia.org/wiki/Picard%E2%80%93Lindel%C3%B6f_theorem">Picard-Lindelöf theorem</a> the solution \(\bfa_\text{aug}(t)\) exists and is unique.</p> <div style="text-align: right">&#x25A1;</div> ]]></content><author><name>Zander W. Blasingame</name></author><category term="diffusion"/><category term="adjoint"/><category term="neuralODEs"/><category term="guided-generation"/><summary type="html"><![CDATA[A short derivation of the continuous adjoint equation for time schedulued conditional variables.]]></summary></entry><entry><title type="html">The Continuous Adjoint Equations for Diffusion Models</title><link href="https://zblasingame.github.io/blog/2024/adjointdeis/" rel="alternate" type="text/html" title="The Continuous Adjoint Equations for Diffusion Models"/><published>2024-11-20T00:00:00+00:00</published><updated>2024-11-20T00:00:00+00:00</updated><id>https://zblasingame.github.io/blog/2024/adjointdeis</id><content type="html" xml:base="https://zblasingame.github.io/blog/2024/adjointdeis/"><![CDATA[<div style="display:none"> $$ \newcommand{\R}{\mathbb{R}} \newcommand{\X}{\mathcal{X}} \newcommand{\Y}{\mathcal{Y}} \newcommand{\B}{\mathcal{B}} \newcommand{\T}{\mathbb{T}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathcal{Z}} \newcommand{\Q}{\mathbb{Q}} \newcommand{\pr}{\mathbb{P}} \newcommand{\bfx}{\mathbf{x}} \newcommand{\bfy}{\mathbf{y}} \newcommand{\bfz}{\mathbf{z}} \newcommand{\bfa}{\mathbf{a}} \newcommand{\bfw}{\mathbf{w}} \newcommand{\bfA}{\mathbf{A}} \newcommand{\bfV}{\mathbf{V}} \newcommand{\bsf}{\boldsymbol{f}} \newcommand{\bsg}{\boldsymbol{g}} \newcommand{\bseps}{\boldsymbol{\epsilon}} \newcommand{\rmd}{\mathrm{d}} \DeclareMathOperator{\var}{Var} \DeclareMathOperator{\ex}{\mathbb{E}} \DeclareMathOperator{\argmax}{arg\,max} \DeclareMathOperator{\argmin}{arg\,min} \newtheorem{proposition}{Proposition} $$ </div> <h2 id="introduction">Introduction</h2> <p>Guided generation is an important problem problem within machine learning. Solutions to this problem enable us to steer the output of the generative process to some desired output. This is especially important for allowing us to inject creative control into generative models. While there are several forms of this problem, we focus on problems which optimize the output of generative model towards some goal defined by a guidance (or loss) function defined on the output. These particular approaches excel in steering the generative process to perform <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learningi">adversarial ML</a> attacks, <em>e.g.</em>, bypassing security features, attacking Face Recognition (FR) systems, <em>&amp;c.</em></p> <p>More formally, suppose we have some \(\R^d\) generative model, \(\bsg_\theta: \R^z \times \R^c \to \R^d\) parameterized by \(\theta \in \R^m\) which takes an initial latent \(\bfz \in \R^z\) and conditional information \(\mathbf{c} \in \R^c\). Furthermore, assume we have a scalar-valued guidance function \(\mathcal{L}: \R^d \to \R\). Then the guided generation problem can be expressed as an optimization problem: \begin{equation} \label{eq:opt_init} \argmin_{\bfz, \mathbf{c}, \theta} \quad \mathcal{L}(\bsg_\theta(\bfz, \mathbf{c})). \end{equation} <em>I.e.</em>, we wish to find the optimal \(\bfz\), \(\mathbf{c}\), and \(\theta\) which minimizes our guidance function. A very natural solution to this kind of problem is to perform <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent</a> by using <a href="https://en.wikipedia.org/wiki/Automatic_differentiation">reverse-mode automatic differentiation</a> to find the gradients.</p> <p>In this blog post, we focus on a technique for finding the gradients for a very popular class of generative models known as <em>diffusion models</em> <d-cite key="song2021denoising,ddpm"></d-cite> by solving the <em>continuous adjoint equations</em> <d-cite key="kidger_thesis"></d-cite>.</p> <h2 id="diffusion-models">Diffusion models</h2> <p>First we give a brief introduction on diffusion models and score-based generative modeling. More comprehensive coverage can be found at <a href="https://yang-song.net/blog/2021/score/">Yang Song’s blog post</a> and <a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">Lilian Weng’s blog post</a> on this topic.</p> <p>Diffusion models start with a diffusion process which perturbs the original data distribution \(p_{\textrm{data}}(\bfx)\) on \(\R^d\) into isotropic Gaussian noise \(\mathcal{N}(\mathbf 0, \mathbf I)\). This process can be modeled with an Itô <a href="https://en.wikipedia.org/wiki/Stochastic_differential_equation">Stochastic Differential Equation</a> (SDE) of the form \begin{equation} \label{eq:ito_diffusion} \mathrm{d}\bfx_t = \underbrace{f(t)\bfx_t\; \mathrm dt}_{\textrm{Deterministic term $\approx$ an ODE}} + \underbrace{g(t)\; \mathrm d\mathbf{w}_t,}_{\textrm{Stochastic term}} \end{equation} where \(f, g\) are real-valued functions, \(\{\bfw_t\}_{t \in [0, T]}\) is the standard <a href="https://en.wikipedia.org/wiki/Wiener_process">Wiener process</a> on time \([0, T]\), and \(\mathrm d\bfw_t\) can be thought of as infinitesimal white noise. The drift coefficient \(f(t)\bfx_t\) is the deterministic part of the SDE and \(f(t)\bfx_t\;\mathrm dt\) can be thought of as the <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ODE</a> term of the SDE. Conversely, the diffusion coefficient \(g(t)\) is the stochastic part of the SDE which controls how much noise is injected into the system. </p> <p>The solution to this SDE is a continuous collection of random variables \(\{\bfx_t\}_{t \in [0, T]}\) over the real interval \([0, T]\), these random variables trace stochastic trajectories over the time interval. Let \(p_t(\bfx_t)\) denote the marginal <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a> of \(\bfx_t\). Then \(p_0(\bfx_0) = p_{\textrm{data}}(\bfx)\) is the data distribution, likewise, for some sufficiently large \(T \in \R\) the terminal distribution \(p_T(\bfx_T)\) is <em>close</em> to some tractable noise distribution \(\pi(\bfx)\), called the <strong>prior distribution</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/diffusion_overview-480.webp 480w,/assets/img/dim/diffusion_overview-800.webp 800w,/assets/img/dim/diffusion_overview-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/diffusion_overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overview of diffusion SDE. Original clean image (left) is slowly perturbed by additions of white noise until there is only noise (right). To sample a clean image from a noisy image we only need to solve the SDE in reverse-time, see Equation \eqref{eq:rev_sde}. </div> <h3 id="reversing-the-diffusion-sde">Reversing the diffusion SDE</h3> <p>So far we have only covered how to destroy data by perturbing it with white noise, however, for sampling we need to be able reverse this process to <em>create</em> data from noise. Remarkably, Anderson <d-cite key="reverse_time_sdes"></d-cite> showed that the Itô SDE in Equation \eqref{eq:ito_diffusion} has a corresponding reverse SDE given in closed form by \begin{equation} \label{eq:rev_sde} \mathrm d\bfx_t = [f(t)\bfx_t - g^2(t)\underbrace{\nabla_\bfx\log p_t(\bfx_t)}_{\textrm{Score function}}]\;\mathrm dt + g(t)\; \mathrm d\bar\bfw_t, \end{equation} where \(\rmd t\) denotes a <em>negative</em> infinitesmial timestep and \(\nabla_\bfx\log p_t(\bfx_t)\) denotes the <strong>score function</strong> of \(p_t(\bfx_t)\). Note, the stochastic term is now driven by a <em>different</em> Wiener process defined on the backwards flow of time, <em>i.e.</em>, \(\bar\bfw_T = \mathbf 0\) a.s.<d-footnote>For technical reasons we use the abbreviation a.s. which denotes almost surely, <i>i.e.</i>, an event happens <i>almost surely</i> if it happens with probability 1. </d-footnote> For a modern derivation of Anderson’s result we recommend checking out the excellent blog post by <a href="https://ludwigwinkler.github.io/blog/ReverseTimeAnderson/">Ludwig Winkler on this topic</a>.</p> <p>To train a diffusion model, then, we just need to learn the score function via score-matching <d-cite key="song2021scorebased"></d-cite> or some closely related quantity like the added noise or \(\bfx_0\)-prediction <d-cite key="ddpm,progressive_distillation"></d-cite>. Many diffusion models use the following choice of drift and diffusion coefficients: \begin{equation} f(t) = \frac{\mathrm d \log \alpha_t}{\mathrm dt},\qquad g^2(t)= \frac{\mathrm d \sigma_t^2}{\mathrm dt} - 2 \frac{\mathrm d \log \alpha_t}{\mathrm dt} \sigma_t^2. \end{equation} Where \(\alpha_t,\sigma_t\) form a noise schedule such that \(\alpha_t^2 + \sigma_t^2 = 1\) and \begin{equation} \bfx_t = \alpha_t\bfx_0 + \sigma_t\boldsymbol\epsilon_t \qquad \boldsymbol\epsilon_t \sim \mathcal{N}(\mathbf 0, \mathbf I). \end{equation} Diffusion models which use noise prediction train a neural network \(\boldsymbol\epsilon_\theta(\bfx_t, t)\) parameterized by \(\theta\) to predict \(\boldsymbol\epsilon_t\) given \(\bfx_t\) which is equivalent to learning \(\boldsymbol\epsilon_\theta(\bfx_t, t) \approx -\sigma_t\nabla_\bfx \log p_t(\bfx_t)\). This choice of drift and coefficients form the Variance Preserving type SDE (VP type SDE) <d-cite key="song2021scorebased"></d-cite>.</p> <h3 id="probability-flow-ode">Probability Flow ODE</h3> <p>Song <em>et al.</em> <d-cite key="song2021scorebased"></d-cite> showed the existence of an ODE, dubbed the <em>Probability Flow</em> ODE, whose trajectories have the same marginals as Equation \eqref{eq:rev_sde} of the form \begin{equation} \label{eq:pf_ode} \frac{\mathrm d\bfx_t}{\mathrm dt} = f(t)\bfx_t - \frac 12 g^2(t) \nabla_\bfx \log p_t(\bfx_t). \end{equation} <em>N.B.</em>, this form can be found by following the derivation used by Anderson <d-cite key="reverse_time_sdes"></d-cite> and manipulating <a href="https://en.wikipedia.org/wiki/Kolmogorov_equations">Kolmogorov equations</a> to write a reverse-time SDE with \(\mathbf 0\) for the diffusion coefficient, <em>i.e.</em>, an ODE.</p> <p>One of key benefits of expressing diffusion models in ODE form is that ODEs are easily reversible, by simply integrating forwards and backwards in time we can encode images from \(p_0(\bfx_0)\) into \(p_T(\bfx_T)\) and back again. With a neural network, often a U-Net <d-cite key="unet"></d-cite>, \(\boldsymbol\epsilon_\theta(\bfx_t, t)\) trained on noise prediction the <em>empirical Probability Flow</em> ODE is now \begin{equation} \label{eq:empirical_pf_ode} \frac{\mathrm d\bfx_t}{\mathrm dt} = f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t} \boldsymbol\epsilon_\theta(\bfx_t, t). \end{equation}</p> <h2 id="guided-generation-for-diffusion-models">Guided generation for diffusion models</h2> <p>Researchers have proposed many ways to perform guided generation with diffusion models. Outside of directly conditioning the noise-prediction network on additional latent information Dhariwal and Nichol proposed classifier guidance <d-cite key="diff_beat_gan"></d-cite> which uses an external classifier \(p(\bfz|\bfx)\) is used to augment the score function \(\nabla_\bfx \log p_t(\bfx_t|\bfz)\). Later work, by Ho and Salimans <d-cite key="ho2021classifierfree"></d-cite> showed the classifier could be omitted by incorporating the conditional information in training with the following parameterization of the noise-prediction model \begin{equation} \tilde{\boldsymbol\epsilon}_\theta(\bfx_t, \bfz, t) := \gamma \boldsymbol\epsilon_\theta(\bfx_t, \bfz, t) + (1 - \gamma) \boldsymbol\epsilon_\theta(\bfx_t, \mathbf 0, t), \end{equation} where \(\gamma \geq 0\) is the guidance scale.</p> <p>Outside of methods which require the additional to the diffusion model, or some external network, there are <strong>training-free methods</strong> which we broadly categorize into the following two categories:</p> <ol> <li>Techniques which directly optimize the solution trajectory during sampling <d-cite key="yu2023freedom,greedy_dim,liu2023flowgrad"></d-cite>.</li> <li>Techniques which search for the optimal generation parameters, <em>e.g.</em>, \((\bfx_T, \bfz, \theta)\), (this can include optimizing the solution trajectory as well) <d-cite key="doodl,pan2024adjointdpm,adjointdeis,marion2024implicit"></d-cite>.</li> </ol> <p>The second solution of techniques is related to our initial problem statement in the introduction from Equation \eqref{eq:opt_init}. We reframe this problem for the specific case of diffusion ODEs.</p> <p><strong>Problem statement.</strong> Given the diffusion ODE in Equation \eqref{eq:empirical_pf_ode}, we wish to solve the following optimization problem: \begin{equation} \label{eq:problem_stmt_ode} \argmin_{\bfx_T, \bfz, \theta}\quad \mathcal{L}\bigg(\bfx_T + \int_T^0 f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t}\bseps_\theta(\bfx_t, \bfz, t)\;\rmd t\bigg). \end{equation} <em>N.B.</em>, without loss of generality we let \(\bseps_\theta(\bfx_t, \bfz, t)\) denote a noise-prediction network conditioned either directly on \(\bfz\) or as the classifier-free guidance model \(\tilde \bseps_\theta(\bfx_t, \bfz, t)\).</p> <p>From this formulation it is readily apparent the difficulty introduced by diffusion models, over say other methods like <a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">GANs</a> or <a href="https://en.wikipedia.org/wiki/Variational_autoencoder">VAEs</a>, is that we need to perform backpropagation through an ODE solve. Luckily, diffusion models are a type of Neural ODE <d-cite key="neural_ode"></d-cite> which means we can solve the <em>continuous adjoint equations</em> to calculate these gradients.</p> <h2 id="continuous-adjoint-equations-for-diffusion-models">Continuous adjoint equations for diffusion models</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/adjointdeis/overview-480.webp 480w,/assets/img/adjointdeis/overview-800.webp 800w,/assets/img/adjointdeis/overview-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/adjointdeis/overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overview of solving the continuous adjoint equations with diffusion models. The sampling schedule consists of <i>N</i> timesteps for the diffusion model and <i>M</i> timesteps for solving the continuous adjoint equations. In this example we use the AdjointDEIS solver for the continuous adjoint equations<d-cite key="adjointdeis"></d-cite>. </div> <p>The technique of solving an <em>adjoint</em> backwards-in-time ODE to calculate the gradients of an ODE is widely used and widespread technique initially proposed by Pontryagin <em>et al.</em> <d-cite key="adjoint_sensitivity_method"></d-cite>. The technique was recently popularized in the ML community by Chen <em>et al.</em> <d-cite key="neural_ode"></d-cite> in their seminal work on Neural ODEs with extensions to other models such as SDEs <d-cite key="adjointsde,kidger_thesis"></d-cite>.</p> <p>We can write the diffusion ODE as a Neural ODE of the form: \(\begin{equation} \frac{\rmd \bfx_t}{\rmd t} = \bsf_\theta(\bfx_t, \bfz, t) := f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t}\bseps(\bfx_t, \bfz, t). \end{equation}\) Then \(\bsf_\theta(\bfx_t, \bfz, t)\) and assuming \(\bsf_\theta\) is continuous in $t$ and uniformly Lipschitz in \(\bfx\),<d-footnote>These conditions are to ensure that the Picard-Lindelo&#776;f theorem holds guaranteeing a unique solution to the IVP. </d-footnote> then \(\bsf_\theta(\bfx_t, \bfz, t)\) describes a neural ODE which has a unique solution with the initial condition \(\bfx_T\) and admits an adjoint state \(\bfa_\bfx(t) := \partial\mathcal{L} / \partial \bfx_t\) (and likewise for \(\bfa_\bfz(t)\) and \(\bfa_\theta(t)\)), which solve the continuous adjoint equations, see Theorem 5.2 in <d-cite key="kidger_thesis"></d-cite>, in the form of the <a href="https://en.wikipedia.org/wiki/Initial_value_problem">Initial Value Problem</a> (IVP): \(\begin{align} \bfa_{\bfx}(0) &amp;= \frac{\partial \mathcal{L}}{\partial \bfx_0}, \qquad &amp;&amp; \frac{\rmd \bfa_{\bfx}}{\rmd t}(t) = -\bfa_{\bfx}(t)^\top \frac{\partial \bsf_\theta(\bfx_t, \bfz, t)}{\partial \bfx_t},\nonumber \\ \bfa_{\bfz}(0) &amp;= \mathbf 0, \qquad &amp;&amp; \frac{\rmd \bfa_{\bfz}}{\rmd t}(t) = -\bfa_{\bfx}(t)^\top \frac{\partial \bsf_\theta(\bfx_t, \bfz, t)}{\partial \bfz},\nonumber \\ \bfa_{\theta}(0) &amp;= \mathbf 0, \qquad &amp;&amp; \frac{\rmd \bfa_{\theta}}{\rmd t}(t) = -\bfa_{\bfx}(t)^\top \frac{\partial \bsf_\theta(\bfx_t, \bfz, t)}{\partial \theta}. \label{eq:adjoint_ode} \end{align}\) We call this augmented ODE system an adjoint diffusion ODE. The adjoint state models the following gradients:</p> <ul> <li>\(\bfa_\bfx(t) := \partial \mathcal L / \partial \bfx_t\). The gradient of the guidance function w.r.t. solution trajectory at any time \(t\).</li> <li>\(\bfa_\bfz(T) := \partial \mathcal L / \partial \bfz\). The gradient of the guidance function w.r.t. the model conditional information.</li> <li>\(\bfa_\theta(T) := \partial \mathcal L / \partial \theta\). The gradient of the guidance function w.r.t. the model parameters.</li> </ul> <p>While this formulation can calculate the desired gradients to solve the optimization problem it, however, fails to account of the unique construction of diffusion models in particular the special formulation of \(f\) and \(g\). Recent work <d-cite key="pan2024adjointdpm,adjointdeis"></d-cite> has shown that by taking this construction into consideration the adjoint diffusion ODE can be considerably simplified enabling the creation of efficient solvers for the continuous adjoint equations.</p> <details><summary>Note on the flow of time</summary> <p>In the literature of diffusion models the sampling process is often done in reverse-time, <em>i.e.</em>, the initial noise is \(\bfx_T\) and the final sample is \(\bfx_0\). Due to this convention solving the adjoint diffusion ODE <em>backwards</em> actually means integrating <em>forwards</em> in time. Thus while diffusion models learn to compute \(\bfx_t\) from \(\bfx_s\) with \(s &gt; t\), the adjoint diffusion ODE seeks to compute \(\bfa_\bfx(s)\) from \(\bfa_\bfx(t)\).</p> </details> <h3 id="simplified-formulation">Simplified formulation</h3> <p>Recent work on efficient ODE solvers for diffusion models <d-cite key="dpm_solver,deis_georgiatech"></d-cite> have shown that by using <em>exponential integrators</em> <d-cite key="exponential_integrators"></d-cite> diffusion ODEs can be simplified and the error in the linear term removed entirely. Likewise, <d-cite key="pan2024adjointdpm,adjointdeis"></d-cite> showed that this same property follows for adjoint diffusion ODEs.</p> <p>The continuous adjoint equation for \(\bfa_\bfx(t)\) in Equation \eqref{eq:adjoint_ode} can be rewritten as \(\begin{equation} \label{eq:empirical_adjoint_ode} \frac{\mathrm d\bfa_\bfx}{\mathrm dt}(t) = -f(t)\bfa_\bfx(t) - \frac{g^2(t)}{2\sigma_t}\bfa_\bfx(t)^\top \frac{\partial \bseps_\theta(\bfx_t, \bfz, t)}{\partial \bfx_t}. \end{equation}\)</p> <p>Due to the gradient of the drift term in Equation \eqref{eq:empirical_adjoint_ode}, further manipulations are required to put the empirical adjoint probability flow ODE into a sufficiently ``nice’’ form. We can transform this <a href="https://en.wikipedia.org/wiki/Stiff_equation">stiff ODE</a> into a non-stiff form by applying the integrating factor \(\exp\big({\int_0^t f(\tau)\;\mathrm d\tau}\big)\) to Equation \eqref{eq:empirical_adjoint_ode}, which is expressed as: \(\begin{equation} \label{eq:empirical_adjoint_ode_IF} \frac{\mathrm d}{\mathrm dt}\bigg[e^{\int_0^t f(\tau)\;\mathrm d\tau} \bfa_\bfx(t)\bigg] = -e^{\int_0^t f(\tau)\;\mathrm d\tau} \frac{g^2(t)}{2\sigma_t}\bfa_\bfx(t)^\top \frac{\partial \bseps_\theta(\bfx_t, \bfz, t)}{\partial \bfx_t}. \end{equation}\) Then, the exact solution at time \(s\) given time \(t &lt; s\) is found to be \(\begin{align} \bfa_\bfx(s) = \underbrace{\vphantom{\int_t^s}e^{\int_s^t f(\tau)\;\mathrm d\tau} \bfa_\bfx(t)}_{\textrm{linear}} - \underbrace{\int_t^s e^{\int_s^u f(\tau)\;\mathrm d\tau} \frac{g^2(u)}{2\sigma_u} \bfa_\bfx(u)^\top \frac{\bseps_\theta(\bfx_u, \bfz, u)}{\partial \bfx_u}\;\rmd u}_{\textrm{non-linear}}. \label{eq:empirical_adjoint_ode_x} \end{align}\) With this transformation we can compute the linear in closed form, thereby <strong>eliminating</strong> the discretization error in the linear term. However, we still need to approximate the non-linear term which consists of a difficult integral about the complex noise-prediction model. This is where the insight of Lu <em>et al.</em> <d-cite key="dpm_solver"></d-cite> to integrate in the log-SNR domain becomes invaluable. Let \(\lambda_t := \log(\alpha_t/\sigma_t)\) be one half of the log-SNR. Then, with using this new variable and computing the drift and diffusion coefficients in closed form, we can rewrite Equation \eqref{eq:empirical_adjoint_ode_x} as \(\begin{equation} \label{eq:empirical_adjoint_ode_x2} \bfa_\bfx(s) = \frac{\alpha_t}{\alpha_s} \bfa_\bfx(t) + \frac{1}{\alpha_s}\int_t^s \alpha_u\sigma_u \frac{\rmd \lambda_u}{\rmd u} \bfa_\bfx(u)^\top \frac{\bseps_\theta(\bfx_u, \bfz, u)}{\partial \bfx_u}\;\rmd u. \end{equation}\) As \(\lambda_t\) is a strictly decreasing function w.r.t. \(t\) it therefore has an inverse function \(t_{\lambda}\) which satisfies \(t_{\lambda}(\lambda_t) = t\), and, with abuse of notation, we let \(\bfx_{\lambda} := \bfx_{t_\lambda(\lambda)}\), \(\bfa_\bfx(\lambda) := \bfa_\bfx(t_{\lambda}(\lambda))\), <em>&amp;c.</em> and let the reader infer from context if the function is mapping the log-SNR back into the time domain or already in the time domain. Then by rewriting Equation \eqref{eq:empirical_adjoint_ode_x2} as an exponentially weighted integral and performing an analogous derivation for \(\bfa_\bfz(t)\) and \(\bfa_\theta(t)\), we arrive at:</p> <p><strong>Proposition</strong> <em>(Exact solution of adjoint diffusion ODEs)</em><strong>.</strong> Given initial values \([\bfa_\bfx(t), \bfa_\bfz(t), \bfa_\theta(t)]\) at time \(t \in (0,T)\), the solution \([\bfa_\bfx(s), \bfa_\bfz(s), \bfa_\theta(s)]\) at time \(s \in (t, T]\) of adjoint diffusion ODEs in Equation \eqref{eq:adjoint_ode} is \(\begin{align} \label{eq:exact_sol_empirical_adjoint_ode_x} \bfa_\bfx(s) &amp;= \frac{\alpha_t}{\alpha_s} \bfa_\bfx(t) + \frac{1}{\alpha_s}\int_{\lambda_t}^{\lambda_s} \alpha_\lambda^2 e^{-\lambda} \bfa_\bfx(\lambda)^\top \frac{\partial \bseps_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \bfx_\lambda}\;\rmd \lambda,\\ \label{eq:exact_sol_empirical_adjoint_ode_z} \bfa_\bfz(s) &amp;= \bfa_\bfz(t) + \int_{\lambda_t}^{\lambda_s}\alpha_\lambda e^{-\lambda} \bfa_\bfx(\lambda)^\top \frac{\partial \boldsymbol\epsilon_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \bfz}\;\rmd\lambda,\\ \label{eq:exact_sol_empirical_adjoint_ode_theta} \bfa_\theta(s) &amp;= \bfa_\theta(t) + \int_{\lambda_t}^{\lambda_s}\alpha_\lambda e^{-\lambda} \bfa_\bfx(\lambda)^\top \frac{\partial \boldsymbol\epsilon_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \theta}\;\rmd\lambda. \end{align}\)</p> <h3 id="numerical-solvers">Numerical solvers</h3> <p>Now that we have a simplified formulation of the continuous adjoint equations we can construct bespoke numerical solvers. To do this we take approximate the integral term via a Taylor expansion which we illustrate for Equation \eqref{eq:exact_sol_empirical_adjoint_ode_x}.For \(k \geq 1\) a \((k-1)\)-th Taylor expansion of the scaled vector Jacobian about \(\lambda_t\) is equal to</p> <div class="l-body-outset"> $$\begin{equation} \alpha_\lambda^2\bfa_\bfx(\lambda)^\top \frac{\partial \boldsymbol\epsilon_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \bfx_\lambda} = \sum_{n=0}^{k-1} \frac{(\lambda - \lambda_t)^n}{n!} \frac{\mathrm d^n}{\mathrm d\lambda^n}\bigg[\alpha_\lambda^2\bfa_\bfx(\lambda)^\top \frac{\partial \boldsymbol\epsilon_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \bfx_\lambda}\bigg]_{\lambda = \lambda_t} + \mathcal{O}((\lambda - \lambda_t)^k). \end{equation}$$ </div> <p>For notational convenience we denote the $n$-th order derivative of scaled vector-Jacobian products at \(\lambda_t\) as \(\begin{equation} \label{eq:app:vjp_def_x} \bfV^{(n)}(\bfx; \lambda_t) = \frac{\rmd^n}{\rmd \lambda^n}\bigg[\alpha_\lambda^2\bfa_\bfx(\lambda)^\top \frac{\partial \bseps_\theta(\bfx_\lambda, \bfz, \lambda)}{\partial \bfx_\lambda}\bigg]_{\lambda = \lambda_t}. \end{equation}\) Then substituting our Taylor expansion into Equation \eqref{eq:exact_sol_empirical_adjoint_ode_x} and letting \(h = \lambda_s - \lambda_t\) denote the step size we have a \(k\)-th order solver for the continuous adjoint equation for \(\bfa_\bfx(t)\):</p> <div class="l-body-outset"> $$\begin{equation} \bfa_\bfx(s) = \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) }_{\substack{\textrm{Linear term}\\\textbf{Exactly computed}}} +\frac{1}{\alpha_s} \sum_{n=0}^{k-1} \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \bfV^{(n)}(\bfx; \lambda_t) }_{\substack{\textrm{Derivatives}\\\textbf{Approximated}}}\; \underbrace{ \int_{\lambda_t}^{\lambda_s} \frac{(\lambda - \lambda_t)^n}{n!} e^{-\lambda}\;\mathrm d\lambda }_{\substack{\textrm{Coefficients}\\\textbf{Analytically computed}}} + \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \mathcal{O}(h^{k+1}). }_{\substack{\textrm{Higher-order errors}\\\textbf{Omitted}}} \end{equation}$$ </div> <p>Let’s break this down term by term.</p> <ol> <li> <p><strong>Linear term.</strong> The linear term of the adjoint diffusion ODE can be calculated exactly using ratio of the signal schedule \(\alpha_t / \alpha_s\). As \(\alpha_t \geq \alpha_s\) for \(t \leq s\) this implies \(\alpha_t / \alpha_s \geq 1\). \(\begin{equation*} \bfa_\bfx(s) = {\color{orange}\underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) }_{\substack{\textrm{Linear term}\\\textbf{Exactly computed}}}} +\frac{1}{\alpha_s} \sum_{n=0}^{k-1} \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \bfV^{(n)}(\bfx; \lambda_t) }_{\substack{\textrm{Derivatives}\\\textbf{Approximated}}}\; \underbrace{ \int_{\lambda_t}^{\lambda_s} \frac{(\lambda - \lambda_t)^n}{n!} e^{-\lambda}\;\mathrm d\lambda }_{\substack{\textrm{Coefficients}\\\textbf{Analytically computed}}} + \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \mathcal{O}(h^{k+1}). }_{\substack{\textrm{Higher-order errors}\\\textbf{Omitted}}} \end{equation*}\)</p> </li> <li> <p><strong>Derivatives.</strong> The \(n\)-th order derivatives of scaled vector-Jacobian product can be efficiently estimated using multi-step methods <d-cite key="atkinson2011numerical"></d-cite>. \(\begin{equation*} \bfa_\bfx(s) = \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) }_{\substack{\textrm{Linear term}\\\textbf{Exactly computed}}} +\frac{1}{\alpha_s} \sum_{n=0}^{k-1} {\color{orange}\underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \bfV^{(n)}(\bfx; \lambda_t) }_{\substack{\textrm{Derivatives}\\\textbf{Approximated}}}}\; \underbrace{ \int_{\lambda_t}^{\lambda_s} \frac{(\lambda - \lambda_t)^n}{n!} e^{-\lambda}\;\mathrm d\lambda }_{\substack{\textrm{Coefficients}\\\textbf{Analytically computed}}} + \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \mathcal{O}(h^{k+1}). }_{\substack{\textrm{Higher-order errors}\\\textbf{Omitted}}} \end{equation*}\)</p> </li> <li> <p><strong>Coefficients.</strong> The exponentially weighted integral can be analytically computed in closed form. \(\begin{equation*} \bfa_\bfx(s) = \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) }_{\substack{\textrm{Linear term}\\\textbf{Exactly computed}}} +\frac{1}{\alpha_s} \sum_{n=0}^{k-1} \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \bfV^{(n)}(\bfx; \lambda_t) }_{\substack{\textrm{Derivatives}\\\textbf{Approximated}}}\; {\color{orange}\underbrace{ \int_{\lambda_t}^{\lambda_s} \frac{(\lambda - \lambda_t)^n}{n!} e^{-\lambda}\;\mathrm d\lambda }_{\substack{\textrm{Coefficients}\\\textbf{Analytically computed}}}} + \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \mathcal{O}(h^{k+1}). }_{\substack{\textrm{Higher-order errors}\\\textbf{Omitted}}} \end{equation*}\)</p> </li> <li> <p><strong>Higher-order errors.</strong> The remaining higher-order error terms are discarded. If \(h^{k+1}\) is sufficiently small than these errors are negligible. \(\begin{equation*} \bfa_\bfx(s) = \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) }_{\substack{\textrm{Linear term}\\\textbf{Exactly computed}}} +\frac{1}{\alpha_s} \sum_{n=0}^{k-1} \underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \bfV^{(n)}(\bfx; \lambda_t) }_{\substack{\textrm{Derivatives}\\\textbf{Approximated}}}\; \underbrace{ \int_{\lambda_t}^{\lambda_s} \frac{(\lambda - \lambda_t)^n}{n!} e^{-\lambda}\;\mathrm d\lambda }_{\substack{\textrm{Coefficients}\\\textbf{Analytically computed}}} + {\color{orange}\underbrace{ \vphantom{\int_{\lambda_t}^{\lambda_s}} \mathcal{O}(h^{k+1}). }_{\substack{\textrm{Higher-order errors}\\\textbf{Omitted}}}} \end{equation*}\)</p> </li> </ol> <details><summary>Computing the exponentially weighted integral</summary> <p>The exponentially weighted integral can be solved <strong>analytically</strong> by applying \(n\) times integration by parts <d-cite key="dpm_solver,exponential_integrators"></d-cite> such that \(\begin{equation} \label{eq:exponential_integral} \int_{\lambda_t}^{\lambda_s} e^{-\lambda} \frac{(\lambda - \lambda_t)^n}{n!}\;\mathrm d\lambda = \frac{\sigma_s}{\alpha_s} h^{n+1}\varphi_{n+1}(h), \end{equation}\) with special \(\varphi\)-functions <d-cite key="exponential_integrators"></d-cite>. These functions are defined as \(\begin{equation} \varphi_{n+1}(h) := \int_0^1 e^{(1-u)h} \frac{u^n}{n!}\;\mathrm du,\qquad\varphi_0(h) = e^h, \end{equation}\) which satisfy the recurrence relation \(\varphi_{k+1}(h) = (\varphi_{k}(h) - \varphi_k(0)) / h\) and have closed forms for \(k = 1, 2\): \(\begin{align} \varphi_1(h) &amp;= \frac{e^h - 1}{h},\\ \varphi_2(h) &amp;= \frac{e^h - h - 1}{h^2}. \end{align}\)</p> </details> <p>From this construction there are only two-sources of error. The error in approximating the \(n\)-th order derivative of the vector-Jacobian and the higher-order errors. Therefore, as we long as we pick a sufficiently small step size, \(h\), and appropriate order, \(k\), we can achieve accurate (enough) estimates of the gradients. The derivations for the solvers of \(\bfa_\bfz(t)\) and \(\bfa_\theta(t)\) are omitted for brevity but follow an analogous derivation. The \(k\)-th order solvers resulting from this method are called <strong>AdjointDEIS-\(k\)</strong>. In <d-cite key="adjointdeis"></d-cite> we prove that that AdjointDEIS-\(k\) are \(k\)-th order solvers for \(k = 1, 2\).</p> <h3 id="implementation">Implementation</h3> <p>Consider the case when \(k=1\) then we have the following first-order solver.</p> <p><strong>AdjointDEIS-1.</strong> Given an initial augmented adjoint state \([\bfa_\bfx(t), \bfa_\bfz(t), \bfa_\theta(t)]\) at time \(t \in (0, T)\), the solution \([\bfa_\bfx(s), \bfa_\bfz(s), \bfa_\theta(s)]\) at time \(s \in (t, T]\) is approximated by \(\begin{align} \bfa_\bfx(s) &amp;= \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t) + \sigma_s (e^h - 1) \frac{\alpha_t^2}{\alpha_s^2}\bfa_\bfx(t)^\top \frac{\partial \bseps(\bfx_t, \bfz, t)}{\partial \bfx_t},\nonumber\\ \bfa_\bfz(s) &amp;= \bfa_\bfz(t) + \sigma_s (e^h - 1) \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t)^\top \frac{\partial \bseps(\bfx_t, \bfz, t)}{\partial \bfz},\nonumber\\ \bfa_\theta(s) &amp;= \bfa_\theta(t) + \sigma_s (e^h - 1) \frac{\alpha_t}{\alpha_s}\bfa_\bfx(t)^\top \frac{\partial \bseps(\bfx_t, \bfz, t)}{\partial \theta}. \label{eq:adjoint_deis_1_at} \end{align}\)</p> <p>The vector-Jacobian product can be easily calculated using reverse-mode automatic differentiation provided by most modern ML frameworks. We illustrate an implementation of this first-order solver using PyTorch. For simplicity we omit the code for calculating \(\bfa_\theta\) as it requires more boilerplate code.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">adjointdeis_1</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">guidance_function</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    Args:
        model (torch.nn.Module): Noise prediction model takes `(x, z, t)` as inputs.
        scheduler: Object which manages the noise schedule and sampling solver for the diffusion model.
        x0 (torch.Tensor): Generated image `x0`.
        z (torch.Tensor): Conditional information.
        guidance_function: A scalar-valued guidance function which takes `x0` as input.
        timesteps (torch.Tensor): A sequence of strictly monotonically increasing timesteps.
    </span><span class="sh">"""</span>
    <span class="n">x0</span><span class="p">.</span><span class="nf">requires_grad_</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">adjoint_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="nf">guidance_function</span><span class="p">(</span><span class="n">x0</span><span class="p">).</span><span class="nf">mean</span><span class="p">(),</span> <span class="n">x0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">adjoint_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
    <span class="n">xt</span> <span class="o">=</span> <span class="n">x0</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">t</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">t</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">timesteps</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>

        <span class="n">model_out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="c1"># Compute vector Jacobians
</span>        <span class="n">vec_J_xt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">model_out</span><span class="p">,</span> <span class="n">xt</span><span class="p">,</span> <span class="n">adjoint_x</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="bp">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">vec_J_z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">autograd</span><span class="p">.</span><span class="nf">grad</span><span class="p">(</span><span class="n">model_out</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">adjoint_z</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="c1"># Compute noise schedule parameters
</span>        <span class="n">lambda_t</span><span class="p">,</span> <span class="n">lambda_s</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">lambda_t</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
        <span class="n">alpha_t</span><span class="p">,</span> <span class="n">alpha_s</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">alpha_t</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>
        <span class="n">sigma_t</span><span class="p">,</span> <span class="n">sigma_s</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">sigma_t</span><span class="p">([</span><span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">])</span>

        <span class="n">h</span> <span class="o">=</span> <span class="n">lambda_s</span> <span class="o">-</span> <span class="n">lambda_t</span>

        <span class="c1"># Solve AdjointDEIS-1
</span>        <span class="n">adjoint_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_t</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">adjoint_x</span> <span class="o">+</span> <span class="n">sigma_s</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">expm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha_t</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">vec_J_xt</span>
        <span class="n">adjoint_z</span> <span class="o">=</span> <span class="n">adjoint_z</span> <span class="o">+</span> <span class="n">sigma_s</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">expm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha_t</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">vec_J_xt</span>

        <span class="c1"># Use some ODE solver to find next xt
</span>        <span class="n">xt</span> <span class="o">=</span> <span class="n">scheduler</span><span class="p">.</span><span class="nf">step</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">xt</span><span class="p">,</span> <span class="n">adjoint_x</span><span class="p">,</span> <span class="n">adjoint_z</span></code></pre></figure> <h3 id="adjoint-diffusion-sdes-are-actually-odes">Adjoint diffusion SDEs are actually ODEs</h3> <p>What about diffusion SDEs, the problem statement in Equation \eqref{eq:problem_stmt_ode} would become \(\begin{equation} \label{eq:problem_stmt_sde} \argmin_{\bfx_T, \bfz, \theta}\quad \mathcal{L}\bigg(\bfx_T + \int_T^0 f(t)\bfx_t + \frac{g^2(t)}{\sigma_t}\bseps_\theta(\bfx_t, \bfz, t)\;\rmd t + \int_T^0 g(t) \; \rmd \bar\bfw_t\bigg). \end{equation}\) The technical details of working with SDEs are beyond the scope of this post; however, we will highlight one of the key insights from our work <d-cite key="adjointdeis"></d-cite>.</p> <p>Suppose we have an SDE in the <a href="https://en.wikipedia.org/wiki/Stratonovich_integral">Stratonovich</a> sense of the form \(\begin{equation} \label{eq:stratonovich_sde} \rmd \bfx_t = \bsf(\bfx_t, t)\;\rmd t + \bsg(t) \circ \rmd \bfw_t \end{equation}\) where \(\circ \rmd \bfw_t\) denotes integration in the Stratonovich sense and \(\bsf \in \mathcal{C}_b^{\infty, 1}(\R^d)\), <em>i.e.</em>, \(\bsf\) is continuous function to \(\R^d\) and has infinitely many bounded derivatives w.r.t. the state and bounded first derivatives w.r.t. to time. Likewise, let \(\bsg \in \mathcal{C}_b^1(\R^{d \times w})\) be a continuous function with bounded first derivatives. Lastly, let \(\bfw_t: [0,T] \to \R^w\) be a \(w\)-dimensional Wiener process. Then Equation \eqref{eq:stratonovich_sde} has unique strong solution given by \(\bfx_t: [0, T] \to \R^d\).</p> <p>We show in <d-cite key="adjointdeis"></d-cite> that the continuous adjoint equations of such an SDE reduce to a backwards-in-time SDE of the form \(\begin{equation} \label{eq:sde_is_ode} \rmd \bfa_\bfx(t) = -\bfa_\bfa(t)^\top \frac{\partial \bsf}{\partial \bfx_t}(\bfx_t, t)\;\rmd t \end{equation}\) with a \(\mathbf 0\) coefficient for the diffusion term and that there exists a unique strong solution to this SDE of the form \(\bfa_\bfx: [0,T] \to \R^d\). As the diffusion coefficient for this SDE is \(\mathbf 0\) then it is essentially an ODE. While glossing over some technical details this result should be straightforwardly apparent as the diffusion coefficient \(\bsg(t)\) relies only on time and not the state, nor other parameters of interest.</p> <p><strong>Remark.</strong> While the adjoint state evolves with an ODE the underlying state \(\bfx_t\) still evolves with a backwards-in-time SDE! This was the reason for our choice of Stratonovich over Itô as the Stratonovich integral is symmetric.</p> <p>Now our diffusion SDE can be easily converted into Stratonovich form due to the diffusion coefficient depending only on time. Moreover, due to the shared derivation using the Kolmogorov equations in constructing diffusion SDEs and diffusion ODEs, the two forms differ only by a factor of 2 within the drift term. \(\begin{equation} {\color{orange}\underbrace{\rmd \bfx_t = f(t)\bfx_t + {\color{cyan}2} \frac{g^2(t)}{2\sigma_t} \bseps_\theta(\bfx_t, \bfz, t)\;\rmd t}_{\textrm{Diffusion ODE}}} + {\color{cyan}g(t)\circ\rmd\bar\bfw_t.} \end{equation}\) Furthermore, notice that SDE has form \(\begin{equation} \rmd \bfx_t = {\color{orange}\underbrace{f(t)\bfx_t + \frac{g^2(t)}{\sigma_t} \bseps_\theta(\bfx_t, \bfz, t)}_{= \bsf_\theta(\bfx_t,\bfz, t)}}\;\rmd t + g(t)\circ\rmd\bar\bfw_t. \end{equation}\) and then by our result from Equation \eqref{eq:sde_is_ode} the adjoint diffusion SDE evolves with the following ODE \(\begin{equation} \frac{\rmd \bfa_\bfx}{\rmd t}(t) = -\bfa_\bfx(t)^\top \frac{\partial \bsf_\theta(\bfx_t, \bfz, t)}{\partial \bfx_t}. \end{equation}\)</p> <p>As the only difference between \(\bsf_\theta\) for diffusion SDEs and ODEs are a factor of 2 we realize that:</p> <blockquote> <p>We can use the <strong>same</strong> ODE solvers for adjoint diffusion SDEs!</p> </blockquote> <p>With the only caveat being the factor of 2. Therefore, we can modify the update equations from our code from above to now solve adjoint diffusion SDEs.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">adjoint_x</span> <span class="o">=</span> <span class="p">(</span><span class="n">alpha_t</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">adjoint_x</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma_s</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">expm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha_t</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="n">vec_J_xt</span>
<span class="n">adjoint_z</span> <span class="o">=</span> <span class="n">adjoint_z</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">sigma_s</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="nf">expm1</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">alpha_t</span> <span class="o">/</span> <span class="n">alpha_s</span><span class="p">)</span> <span class="o">*</span> <span class="n">vec_J_xt</span></code></pre></figure> <h2 id="concluding-remarks">Concluding remarks</h2> <p>This blog post gives a detailed introduction to the continuous adjoint equations. We discuss the theory behind them and why it is an appropriate tool for solving guided generation problems for diffusion models. This post serves as a summary for our recent NeurIPS paper:</p> <ul> <li><a href="https://openreview.net/forum?id=fAlcxvrOEX">Zander W. Blasingame and Chen Liu. <em>AdjointDEIS: Efficient Gradients for Diffusion Models</em>. NeurIPS 2024</a></li> </ul> <p>For examples of this technique used in practice check out our full paper and concurrent work from our colleagues <d-cite key="marion2024implicit,pan2024adjointdpm"></d-cite> which explore different experiements and focus on different aspects of implementing the continuous adjoint equations.</p>]]></content><author><name>Zander W. Blasingame</name></author><category term="diffusion"/><category term="adjoint"/><category term="neuralODEs"/><category term="guided-generation"/><summary type="html"><![CDATA[This blog introduces the topic of the continuous adjoint equations for diffusion models, an efficient way to calculate gradients for diffusion models. We show how to design bespoke ODE/SDE solvers of the continuous adjoint equations and show that adjoint diffusion SDEs actually simplify to the adjoint diffusion ODE.]]></summary></entry><entry><title type="html">Face Morphing with Diffusion Models</title><link href="https://zblasingame.github.io/blog/2024/face-morphing-dim/" rel="alternate" type="text/html" title="Face Morphing with Diffusion Models"/><published>2024-08-27T00:00:00+00:00</published><updated>2024-08-27T00:00:00+00:00</updated><id>https://zblasingame.github.io/blog/2024/face-morphing-dim</id><content type="html" xml:base="https://zblasingame.github.io/blog/2024/face-morphing-dim/"><![CDATA[ <div style="display:none"> $$ \newcommand{\R}{\mathbb{R}} \newcommand{\X}{\mathcal{X}} \newcommand{\Y}{\mathcal{Y}} \newcommand{\B}{\mathcal{B}} \newcommand{\T}{\mathcal{T}} \newcommand{\N}{\mathbb{N}} \newcommand{\Z}{\mathcal{Z}} \newcommand{\Q}{\mathbb{Q}} \newcommand{\pr}{\mathbb{P}} \newcommand{\bfx}{\mathbf{x}} \newcommand{\bfy}{\mathbf{y}} \newcommand{\bfz}{\mathbf{z}} \newcommand{\bfa}{\mathbf{a}} \newcommand{\bfw}{\mathbf{w}} \DeclareMathOperator{\var}{Var} \DeclareMathOperator{\ex}{\mathbb{E}} \DeclareMathOperator{\argmax}{arg\,max} \DeclareMathOperator{\argmin}{arg\,min} $$ </div> <h2 id="introduction">Introduction</h2> <p>Face morphing is a kind of attack wherein the attacker attempts to combine the faces of two real identities into <em>one</em> face. This attack exploits the structure of the embedding space of the Face Recognition (FR) system <d-cite key="Ferrara2016,morphed_first"></d-cite>. FR systems generally work by embedding the image which is hard to compare into some kind of vector space which makes it easier to compare, this space is referred to as the feature space of the FR system. Once a user is enrolled into the FR system an acceptance region<d-footnote>If the measure of distance is a proper metric, like $\ell^2$, and not just a semi-metric this forms a ball around the enrolled user.</d-footnote> is defined around the enrolled user in the feature space. If there exists an overlap between the acceptance regions of two identities in the feature space then a face morphing attack can be performed.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/morph_diagram-480.webp 480w,/assets/img/dim/morph_diagram-800.webp 800w,/assets/img/dim/morph_diagram-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/morph_diagram.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overview of the face morphing attack. The goal is to create a morphed face that lies within the acceptance regions of <i>both</i> identities. Bona fide images from the FRLL dataset <d-cite key="frll"></d-cite>. </div> <p>Face morphing attacks fall broadly into two categories.</p> <ul> <li> <p><strong>Landmark-based attacks</strong> create morphed images by warping and aligning facial landmarks of the two face images before performing a pixel-wise average to obtain the morph <d-cite key="can_gan_beat_landmark,multe-scale-block-fusion"></d-cite>.</p> </li> <li> <p><strong>Representation-based attacks</strong> create morphs by first embedding the original images into a representational space, once embedded into this space an interpolation between the two embeddings is constructed to a morphed representation. This morph representation is then projected back into the image space to created the morphed image <d-cite key="morgan"></d-cite>.</p> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/001_03-480.webp 480w,/assets/img/dim/frll/bona_fide/001_03-800.webp 800w,/assets/img/dim/frll/bona_fide/001_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/001_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>a</i></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/opencv/001_013-480.webp 480w,/assets/img/dim/frll/opencv/001_013-800.webp 800w,/assets/img/dim/frll/opencv/001_013-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/opencv/001_013.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">OpenCV <d-cite key="syn-mad22"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/mipgan2/001_013-480.webp 480w,/assets/img/dim/frll/mipgan2/001_013-800.webp 800w,/assets/img/dim/frll/mipgan2/001_013-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/mipgan2/001_013.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">MIPGAN-II <d-cite key="mipgan"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/013_03-480.webp 480w,/assets/img/dim/frll/bona_fide/013_03-800.webp 800w,/assets/img/dim/frll/bona_fide/013_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/013_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>b</i></div> </div> </div> <div class="caption"> Comparison between a landmark-based morph (OpenCV) and representation-based morph (MIPGAN-II). </div> <p>Historically, representation-based morphs have been created using Generative Adversarial Networks (GANs) <d-cite key="gan"></d-cite> a type of generative model which learns a mapping from the representation space to image space in an adversarial manner. One challenge to figure out with GAN-based morphing is learning how to embed the original images into the representation space. Researchers have proposed several techniques for this ranging from training an encoder network jointly with the GAN <d-cite key="bigan,aae,alae"></d-cite>, training an additional encoding network <d-cite key="e4e"></d-cite>, to inverting an image into the representation space via optimization <d-cite key="gan_opt_invert,Abdal_2019_ICCV"></d-cite>. Once the original faces are mapped into the representation space, the representations can be morphed using linear interpolation <d-cite key="morgan"></d-cite> and additionally optimized w.r.t. some identity loss <d-cite key="mipgan"></d-cite>.</p> <p>Landmark-based attacks are simple and surprisingly effective <d-cite key="sebastien_gan_threaten"></d-cite> when compared to representation-based attacks. However, they struggle with prominent visual artefacts—especially outside the central face region. While representation-based attacks do not suffer from the glaring visual artefacts which plague the landmark-based attacks, their ability to fool an FR system is severely lacking <d-cite key="sebastien_gan_threaten"></d-cite>.</p> <p>In this blog post, I introduce a novel family of representation-based attacks collectively known as <strong>Di</strong>fusion <strong>M</strong>orphs (<strong>DiM</strong>) which addresses both the issues of prominent visual artefacts and inability to adequately fool an FR system. The key idea is to use a type of iterative generative model known as <em>diffusion models</em> or <em>score-based models</em> <d-cite key="song2021scorebased"></d-cite>. DiMs have achieved state-of-the-art performance on the face morphing tasks <d-cite key="blasingame_dim,fast_dim,greedy_dim"></d-cite> and have even yielded insight on related tasks, <em>e.g.</em>, guided generation of diffusion models <d-cite key="greedy_dim"></d-cite>.</p> <h2 id="diffusion">Diffusion</h2> <p>Diffusion models start with a diffusion process which perturbs the original data distribution \(p(\bfx)\) on same subset of Euclidean space \(\X \subseteq \R^n\) into isotropic Gaussian noise \(\mathcal{N}(\mathbf 0, \mathbf I)\). This process can be modeled with an Itô <a href="https://en.wikipedia.org/wiki/Stochastic_differential_equation">Stochastic Differential Equation</a> (SDE) of the form \begin{equation} \mathrm{d}\bfx_t = f(t)\bfx_t\; \mathrm dt + g(t)\; \mathrm d\mathbf{w}_t \end{equation} where \(f, g\) are real-valued functions, \(\{\bfw_t\}_{t \in [0, T]}\) is the standard <a href="https://en.wikipedia.org/wiki/Wiener_process">Wiener process</a> on time \([0, T]\), and \(\mathrm d\bfw_t\) can be thought of as infinitesimal white noise. The drift coefficient \(f(t)\bfx_t\) is the deterministic part of the SDE and \(f(t)\bfx_t\;\mathrm dt\) can be thought of as the <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ODE</a> term of the SDE. Conversely, the diffusion coefficient \(g(t)\) is the stochastic part of the SDE which controls how much noise is injected into the system. We can think of \(g(t)\;\mathrm d\bfw_t\) as the <em>control</em> term of the SDE.</p> <p>The solution to this SDE is a continuous collection of random variables \(\{\bfx_t\}_{t \in [0, T]}\) over the real interval \([0, T]\), these random variables trace stochastic trajectories over the time interval. Let \(p_t(\bfx_t)\) denote the marginal <a href="https://en.wikipedia.org/wiki/Probability_density_function">probability density function</a> of \(\bfx_t\). Then \(p_0(\bfx_0) = p(\bfx)\) is the data distribution, likewise, for some sufficiently large \(T \in \R\) the terminal distribution \(p_T(\bfx_T)\) is <em>close</em> to some tractable noise distribution \(\pi(\bfx)\), called the <strong>prior distribution</strong>.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/diffusion_overview-480.webp 480w,/assets/img/dim/diffusion_overview-800.webp 800w,/assets/img/dim/diffusion_overview-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/diffusion_overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overview of diffusion SDE. Original clean image (left) is slowly perturbed by additions of white noise until there is only noise (right). </div> <h3 id="reversing-the-diffusion-sde">Reversing the diffusion SDE</h3> <p>So far we have only covered how to destroy data by perturbing it with white noise, however, for sampling we need to be able reverse this process to <em>create</em> data from noise. Remarkably, Anderson <d-cite key="anderson_diffusion"></d-cite> showed that any Itô SDE has a corresponding reverse SDE given in closed form by \begin{equation} \label{eq:rev_sde} \mathrm d\bfx_t = [f(t)\bfx_t - g^2(t)\nabla_\bfx\log p_t(\bfx_t)]\;\mathrm dt + g(t)\; \mathrm d\tilde\bfw_t \end{equation} where \(\nabla_\bfx\log p_t(\bfx_t)\) denotes the <strong>score function</strong> of \(p_t(\bfx_t)\). Note, that the <em>control</em> term is now driven by the <em>backwards</em> Wiener process defined as \(\tilde\bfw_t := \bfw_t - \bfw_T\). To train a diffusion model, then, we just need to learn the score function <d-cite key="song2021scorebased"></d-cite> or some closely related quantity like the added noise or \(\bfx_0\)-prediction <d-cite key="ddpm,progressive_distillation"></d-cite>. Many diffusion models used the following choice of drift and diffusion coefficients \begin{equation} f(t) = \frac{\mathrm d \log \alpha_t}{\mathrm dt}\qquad g^2(t)= \frac{\mathrm d \sigma_t^2}{\mathrm dt} - 2 \frac{\mathrm d \log \alpha_t}{\mathrm dt} \sigma_t^2 \end{equation} where \(\alpha_t,\sigma_t\) form a noise schedule such that \(\alpha_t^2 + \sigma_t^2 = 1\) and \begin{equation} \bfx_t = \alpha_t\bfx_0 + \sigma_t\boldsymbol\epsilon_t \qquad \boldsymbol\epsilon_t \sim \mathcal{N}(\mathbf 0, \mathbf I) \end{equation} Diffusion models which use noise prediction train a neural network \(\boldsymbol\epsilon_\theta(\bfx_t, t)\) parameterized by \(\theta\) to predict \(\boldsymbol\epsilon_t\) given \(\bfx_t\) which is equivalent to learning \(\boldsymbol\epsilon_\theta(\bfx_t, t) = -\sigma_t\nabla_\bfx \log p_t(\bfx_t)\). This choice of drift and coefficients forms the Variance Preserving SDE (VP SDE) type of diffusion SDE <d-cite key="song2021scorebased"></d-cite>.</p> <h3 id="probability-flow-ode"><em>Probability Flow</em> ODE</h3> <p>Song <em>et al.</em> <d-cite key="song2021scorebased"></d-cite> showed the existence of an ODE, dubbed the <em>Probability Flow</em> ODE, whose trajectories have the same marginals as Equation \eqref{eq:rev_sde} of the form \begin{equation} \label{eq:pf_ode} \frac{\mathrm d\bfx_t}{\mathrm dt} = f(t)\bfx_t - \frac 12 g^2(t) \nabla_\bfx \log p_t(\bfx_t) \end{equation} One of key benefits of expressing diffusion models in ODE form is that ODEs are easily reversible, by simply integrating forwards and backwards in time we can encode images from \(p_0(\bfx_0)\) into \(p_T(\bfx_T)\) and back again. With a neural network, often a U-Net <d-cite key="unet"></d-cite>, \(\boldsymbol\epsilon_\theta(\bfx_t, t)\) trained on noise prediction the <em>empirical Probability Flow</em> ODE is now \begin{equation} \label{eq:empirical_pf_ode} \frac{\mathrm d\bfx_t}{\mathrm dt} = f(t)\bfx_t + \frac{g^2(t)}{2\sigma_t} \boldsymbol\epsilon_\theta(\bfx_t, t) \end{equation}</p> <h2 id="dim">DiM</h2> <p><strong>Di</strong>fusion <strong>M</strong>orphs (<strong>DiM</strong>) are a novel kind of face morphing algorithm which solve the <em>Probability Flow</em> ODE <em>both</em> forwards and backwards in time to achieve state-of-the-art visual fidelity and morphing performance far surpassing previous representation-based morphing attacks. The DiM framework could use many different diffusion backbones like DDPM <d-cite key="ddpm"></d-cite>, LDM <d-cite key="ldm"></d-cite>, DiT <d-cite key="Peebles2022DiT"></d-cite>, &amp;c. However, in our work we opted to use the Diffusion Autoencoder <d-cite key="diffae"></d-cite> trained on the FFHQ dataset <d-cite key="stylegan"></d-cite> which conditions the noise prediction network \(\boldsymbol\epsilon_\theta(\bfx_t, \bfz, t)\) on a latent representation, \(\bfz\), of the target image.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/dim_overview-480.webp 480w,/assets/img/dim/dim_overview-800.webp 800w,/assets/img/dim/dim_overview-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/dim_overview.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> DiM Face morphing pipeline. </div> <p>Before discussing the DiM pipeline let’s establish some nomenclature. Let \(\bfx_0^{(a)}\) and \(\bfx_0^{(b)}\) denote two bona fide images of identities \(a\) and \(b\). Let \(\Z\) denote the latent vector space and let \(\bfz_a = E(\bfx_0^{(a)})\) denote the latent representation of \(a\) and likewise for \(\bfz_b\) where \(E: \X \to \Z\) is an encoding network <d-cite key="diffae"></d-cite>. Let \(\Phi(\bfx_0, \bfz, \mathbf{h}_\theta, \{t_n\}_{n=1}^N) \mapsto \bfx_T\) denote a numerical ODE solver which takes an initial image \(\bfx_0\), latent representation of \(\bfx_0\) denoted by \(\bfz\), the ODE in Equation \eqref{eq:empirical_pf_ode} denoted by \(\mathrm d\bfx_t / \mathrm dt = \mathbf{h}_\theta(\bfx_t, \bfz, t)\), and timesteps \(\{t_n\}_{n=1}^N \subseteq [0, T]\). Let \(\mathrm{lerp}(\cdot, \cdot; \gamma)\) denote linear interpolation by a weight of \(\gamma\) on the first argument and likewise \(\mathrm{slerp}(\cdot, \cdot; \gamma)\) for <a href="https://en.wikipedia.org/wiki/Slerp">spherical linear interpolation</a>.</p> <p>The DiM pipeline works by first solving the <em>Probability Flow</em> ODE as time flows with \(N_F \in \N\) timesteps forwards for both identities, <em>i.e.</em>, \begin{equation} \bfx_T^{(\{a, b\})} = \Phi(\bfx_0^{(\{a, b\})}, \bfz_{\{a, b\}}, \mathbf{h}_\theta, \{t_n\}_{n=1}^{N_F}) \end{equation} to find the noisy representations of the original images. We then morph both the noisy and latent representations by a factor of \(\gamma = 0.5\) to find \begin{equation} \bfx_T^{(ab)} = \mathrm{slerp}(\bfx_T^{(a)}, \bfx_T^{(b)}; \gamma) \qquad \bfz_{ab} = \mathrm{lerp}(\bfz_a, \bfz_b; \gamma) \end{equation} Then we solve the <em>Probability Flow</em> ODE as time runs <em>backwards</em> with \(N \in \N\) timesteps \(\{\tilde t_n\}_{n=1}^N\) where \(\tilde t_1 = T\) such that \begin{equation} \bfx_0^{(ab)} = \Phi(\bfx_T^{(ab)}, \bfz_{ab}, \mathbf{h}_\theta, \{\tilde t_n\}_{n=1}^{N}) \end{equation}</p> <p>All these equations for the DiM can be summarized with the following PyTorch pseudo code.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="n">ode_solver</span><span class="p">,</span> <span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mf">80.</span><span class="p">,</span> <span class="n">n_encode</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    DiM algorithm.

    Args:
        model (nn.Module): Noise prediction U-Net (or x-prediction / v-prediction).
        encoder (nn.Module): Encoder network.
        diff_eq (function): RHS of Probabilty Flow ODE.
        ode_solver (function): Numerical ODE solver, e.g., RK-4, Adams-Bashforth.
        x_a (torch.Tensor): Image of identity a.
        x_b (torch.Tensor): Image of identity b.
        eps (float): Starting timstep. Defaults to 0.002. For numeric stability.
        T (float): Terminal timestep. Defaults to 80.
        n_encode (int): Number of encoding steps. Defaults to 250.
        n_sample (int): Number of sampling steps. Defaults to 100.

    Returns:
        x_morph (torch.Tensor): The morphed image.
    </span><span class="sh">"""</span>

    <span class="c1"># Create latents
</span>    <span class="n">z_a</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">x_a</span><span class="p">)</span>
    <span class="n">z_b</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">x_b</span><span class="p">)</span>
    
    <span class="c1"># Encode images into noise
</span>    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">n_encode</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="nf">ode_solver</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z_a</span><span class="p">,</span> <span class="n">z_b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span> <span class="o">=</span> <span class="n">xs</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Morph representations
</span>    <span class="n">z_ab</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">lerp</span><span class="p">(</span><span class="n">z_a</span><span class="p">,</span> <span class="n">z_b</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">x_ab</span> <span class="o">=</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># assumes slerp is defined somewhere
</span>
    <span class="c1"># Generate morph
</span>    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">n_sample</span><span class="p">)</span> 
    <span class="n">x_morph</span> <span class="o">=</span> <span class="nf">ode_solver</span><span class="p">(</span><span class="n">x_ab</span><span class="p">,</span> <span class="n">z_ab</span><span class="p">,</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">x_morph</span>
</code></pre></div></div> <p>A few important observations.</p> <ul> <li>The number of encoding steps \(N_F\) does not need to equal to the number of sampling steps \(N\), <em>i.e.</em>, these process are decoupled.</li> <li>We can use separate numerical ODE solvers for encoding and sampling.</li> <li>Samples are iteratively generated, meaning there are more ways to guide the morph generation process</li> </ul> <p>By using the powerful and flexible framework of diffusion models we can achieve <strong>state-of-the-art</strong> visual fidelity and morphing performance (measured in MMPMR<d-footnote>The Mated Morph Presentation Match Rate (MMPMR) <d-cite key="mmpmr"></d-cite> metric is a measure of how vulnerable a FR system is to a morphing attack and is defined as $$M(\delta) = \frac{1}{M} \sum_{n=1}^M \bigg\{\bigg[\min_{n \in \{1,\ldots,N_m\}} S_m^n\bigg] &gt; \delta\bigg\}$$ where $\delta$ is the verification threshold, $S_m^n$ is the similarity score of the $n$-th subject of morph $m$, $N_m$ is the total number of contributing subjects to morph $m$, and $M$ is the total number of morphed images. </d-footnote>). Visually, the morphs produced by DiM look more realistic than the landmark-based morphs with their prominent artefacts and even better than the GAN-based morphs.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/004_03-480.webp 480w,/assets/img/dim/frll/bona_fide/004_03-800.webp 800w,/assets/img/dim/frll/bona_fide/004_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/004_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>a</i></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/opencv/004_012-480.webp 480w,/assets/img/dim/frll/opencv/004_012-800.webp 800w,/assets/img/dim/frll/opencv/004_012-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/opencv/004_012.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">OpenCV <d-cite key="syn-mad22"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/dim_a/004_012-480.webp 480w,/assets/img/dim/frll/dim_a/004_012-800.webp 800w,/assets/img/dim/frll/dim_a/004_012-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/dim_a/004_012.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">DiM <d-cite key="blasingame_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/mipgan2/004_012-480.webp 480w,/assets/img/dim/frll/mipgan2/004_012-800.webp 800w,/assets/img/dim/frll/mipgan2/004_012-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/mipgan2/004_012.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">MIPGAN-II <d-cite key="mipgan"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/012_03-480.webp 480w,/assets/img/dim/frll/bona_fide/012_03-800.webp 800w,/assets/img/dim/frll/bona_fide/012_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/012_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>b</i></div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/009_03-480.webp 480w,/assets/img/dim/frll/bona_fide/009_03-800.webp 800w,/assets/img/dim/frll/bona_fide/009_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/009_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>a</i></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/opencv/009_112-480.webp 480w,/assets/img/dim/frll/opencv/009_112-800.webp 800w,/assets/img/dim/frll/opencv/009_112-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/opencv/009_112.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">OpenCV <d-cite key="syn-mad22"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/dim_a/009_112-480.webp 480w,/assets/img/dim/frll/dim_a/009_112-800.webp 800w,/assets/img/dim/frll/dim_a/009_112-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/dim_a/009_112.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">DiM <d-cite key="blasingame_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/mipgan2/009_112-480.webp 480w,/assets/img/dim/frll/mipgan2/009_112-800.webp 800w,/assets/img/dim/frll/mipgan2/009_112-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/mipgan2/009_112.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">MIPGAN-II <d-cite key="mipgan"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/112_03-480.webp 480w,/assets/img/dim/frll/bona_fide/112_03-800.webp 800w,/assets/img/dim/frll/bona_fide/112_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/112_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>b</i></div> </div> </div> <div class="caption"> Comparison between a morphed image generated via OpenCV, DiM, and MIPGAN-II<d-footnote>Due to the computational demands needed to train a diffusion model on the image space the U-Net we use was trained at a $256 \times 256$ resolution, whereas less computationally demanding morphs are at a higher resolution. This difference is trivial, however, as most images are cropped and down-sampled, <i>e.g.</i>, $112 \times 112$ before being passed to the FR system.</d-footnote>. </div> <table> <thead> <tr> <th style="text-align: left">Morphing Attack</th> <th style="text-align: right">AdaFace</th> <th style="text-align: right">ArcFace</th> <th style="text-align: right">ElasticFace</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">FaceMorpher <d-cite key="syn-mad22"></d-cite></td> <td style="text-align: right">89.78</td> <td style="text-align: right">87.73</td> <td style="text-align: right">89.57</td> </tr> <tr> <td style="text-align: left">OpenCV <d-cite key="syn-mad22"></d-cite></td> <td style="text-align: right">94.48</td> <td style="text-align: right">92.43</td> <td style="text-align: right">94.27</td> </tr> <tr> <td style="text-align: left">MIPGAN-I <d-cite key="mipgan"></d-cite></td> <td style="text-align: right">72.19</td> <td style="text-align: right">77.51</td> <td style="text-align: right">66.46</td> </tr> <tr> <td style="text-align: left">MIPGAN-II <d-cite key="mipgan"></d-cite></td> <td style="text-align: right">70.55</td> <td style="text-align: right">72.19</td> <td style="text-align: right">65.24</td> </tr> <tr> <td style="text-align: left">DiM <d-cite key="blasingame_dim"></d-cite></td> <td style="text-align: right">92.23</td> <td style="text-align: right">90.18</td> <td style="text-align: right">93.05</td> </tr> </tbody> </table> <div class="caption"> Vulnerability of different of FR systems across different morphing attacks on the SYN-MAD 20222 dataset. False Match Rate (FMR) is set at 0.1% for all FR systems. Higher is better. </div> <h3 id="high-order-ode-solvers">High-order ODE solvers</h3> <p>The <em>Probability Flow</em> ODE in Equation \eqref{eq:empirical_pf_ode} can be transformed from a <a href="https://en.wikipedia.org/wiki/Stiff_equation">stiff ODE</a> into a semi-linear ODE by using <em><a href="https://en.wikipedia.org/wiki/Exponential_integrator">exponential integrators</a></em>. Lu <em>et al.</em> <d-cite key="dpm_solver"></d-cite> showed that the exact solution at time \(t\) given \(\bfx_s\) starting from time \(s\) is given by \begin{equation} \bfx_t = \underbrace{\vphantom{\int_{\lambda_s}}\frac{\alpha_t}{\alpha_s}\bfx_s}_{\textrm{analytically computed}} - \alpha_t \underbrace{\int_{\lambda_s}^{\lambda_t} e^{-\lambda} \boldsymbol\epsilon_\theta(\bfx_\lambda, \lambda)\;\mathrm d\lambda}_{\textrm{approximated}} \end{equation} where \(\lambda_t := \log(\alpha_t / \sigma_t)\) is one half the log-<a href="https://en.wikipedia.org/wiki/Signal-to-noise_ratio">SNR</a>. which removes the error for the linear term. The remaining integral term approximated by exploiting the wealth of literature on exponential integrators. E.g., take a \(k\)-th order Taylor expansion around \(\lambda_s\) and apply multi-step methods to approximate the \(n\)-th order derivatives.</p> <p>Previously, DiM used <em>DDIM</em> a first-order ODE solver of the form \begin{equation} \bfx_{t_n} = \frac{\alpha_{t_n}}{\alpha_{t_{n-1}}}\bfx_{t_{n-1}} - \sigma_{t_n}(e^{h_n} - 1)\boldsymbol\epsilon_\theta(\bfx_{t_{n-1}}, \bfz, t_{n-1}) \end{equation} where \(h_n = \lambda_{t_n} - \lambda_{t_{n-1}}\) is the step size of the ODE solver. This, however, means that we have a <a href="https://en.wikipedia.org/wiki/Truncation_error_(numerical_integration)">global truncation error</a> of \(\mathcal{O}(h)\) (Theorem 3.2 in <d-cite key="dpm_solver"></d-cite>). This means that we need a very small step size to keep the error small or, in other words, we need a <strong>large</strong> number of sampling steps to accurate encode <strong>and</strong> sample the <em>Probability Flow</em> ODE. The initial DiM implementation <d-cite key="blasingame_dim"></d-cite> used \(N_F = 250\) encoding steps and \(N = 100\) sampling steps. An initial study we conducted found these to be optimal with the first-order solver.</p> <p>By using a second-order multistep ODE solver <em>DPM++ 2M</em> <d-cite key="lu2023dpmsolver"></d-cite> we can significantly reduce the number of Network Function Evalutions (NFE), <em>i.e.</em>, the number of times we run the neural nework—a very expenesive operation, without meaningfully reducing the performance of the morphing attack. Likewise, the visual impact on the appearance of the morphed face seems to be quite small. Therefore, by switching to a high-order ODE solver we can <strong>significantly</strong> reduce the NFE while retaining comparable performance to vanilla DiM. We call this approach <em>Fast-DiM</em> due to its reduced computational demand.</p> <table> <thead> <tr> <th style="text-align: left">ODE Solver</th> <th style="text-align: right">NFE (↓)</th> <th style="text-align: right">AdaFace (MMPMR ↑)</th> <th style="text-align: right">ArcFace (MMPMR ↑)</th> <th style="text-align: right">ElasticFace (MMPMR ↑)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">DDIM</td> <td style="text-align: right">100</td> <td style="text-align: right">92.23</td> <td style="text-align: right">90.18</td> <td style="text-align: right">93.05</td> </tr> <tr> <td style="text-align: left">DPM++ 2M</td> <td style="text-align: right">50</td> <td style="text-align: right">92.02</td> <td style="text-align: right">90.18</td> <td style="text-align: right">93.05</td> </tr> <tr> <td style="text-align: left">DPM++ 2M</td> <td style="text-align: right">20</td> <td style="text-align: right">91.26</td> <td style="text-align: right">89.98</td> <td style="text-align: right">93.25</td> </tr> </tbody> </table> <div class="caption"> Impact of the ODE solver in the sampling process of DiM. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/fast_dim_ddim_vs_dpm_pp_2m-480.webp 480w,/assets/img/dim/fast_dim_ddim_vs_dpm_pp_2m-800.webp 800w,/assets/img/dim/fast_dim_ddim_vs_dpm_pp_2m-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/fast_dim_ddim_vs_dpm_pp_2m.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> From left to right: face <i>a</i>, morph generated with DDIM <i>(N = 100)</i>, morph generated with DPM++ 2M <i>(N = 20)</i>, face <i>b</i>. </div> <p>While we have shown that by solving the <em>Probability Flow</em> ODE as time runs backwards with high-order solves we can significantly reduce the NFE with no downside, we have yet to explore the impact on the encoding process. Interestingly, we discovered the success of DiM morphs is highly sensitive to the accuracy of the encoding process. Merely, dropping the number of encoding steps from 250 to 100 showed a marked decline in performance; conversely, increasing sampling steps over 100 showed no benefit. We posit that this might be due to the odd nature of the encoded images.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/ddim_encode-480.webp 480w,/assets/img/dim/ddim_encode-800.webp 800w,/assets/img/dim/ddim_encode-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/ddim_encode.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> From left to right: Original image, encoded image, true white noise. The encoded noise has strange artefacts in what was the background of the image and the outline of the head is still visible even when fully encoded into noise. </div> <table> <thead> <tr> <th style="text-align: left">ODE Solver</th> <th style="text-align: right">NFE (↓)</th> <th style="text-align: right">AdaFace (MMPMR ↑)</th> <th style="text-align: right">ArcFace (MMPMR ↑)</th> <th style="text-align: right">ElasticFace (MMPMR ↑)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">DDIM</td> <td style="text-align: right">100</td> <td style="text-align: right">91.82</td> <td style="text-align: right">88.75</td> <td style="text-align: right">91.21</td> </tr> <tr> <td style="text-align: left">DPM++ 2M</td> <td style="text-align: right">100</td> <td style="text-align: right">90.59</td> <td style="text-align: right">87.15</td> <td style="text-align: right">90.8</td> </tr> <tr> <td style="text-align: left">DDIM</td> <td style="text-align: right">50</td> <td style="text-align: right">89.78</td> <td style="text-align: right">86.3</td> <td style="text-align: right">89.37</td> </tr> <tr> <td style="text-align: left">DPM++ 2M</td> <td style="text-align: right">50</td> <td style="text-align: right">90.18</td> <td style="text-align: right">86.5</td> <td style="text-align: right">88.96</td> </tr> </tbody> </table> <div class="caption"> Impact of the ODE solver in the encoding process of DiM. Sampling was all done with DPM++ 2M <i>(N = 50)</i> </div> <h2 id="greedy-guided-generation">Greedy Guided Generation</h2> <p>Identity-guided generation massively improved the effectiveness of GAN-based morphs <d-cite key="mipgan"></d-cite>; however, these techniques relied on being able to solve \begin{equation} \bfz^* = \argmin_{\bfz \in \Z} \quad \mathcal{L}(g(\bfz), \bfx_0^{(a)}, \bfx_0^{(b)}) \end{equation} efficiently w.r.t some loss function \(\mathcal{L}\) with generator network \(g: \Z \to \X\) and requires the gradient \(\partial \mathcal{L} / \partial \bfz\) to perform optimziation in the latent space. However, obtaining an analogous gradient in DiM is not a trivial task due to the iterative generative nature of diffusion models. Naïvely, trying to estimate the gradient by backproping through all the neural network evaluations is horrendously inefficient and will consume the memory of all but the largest of rigs. While there is active research on <em>efficiently</em> estimating the gradients for diffusion models \(\partial \mathcal{L} / \partial \bfx_T\) and \(\partial \mathcal{L} / \partial \bfz\), see Marion <em>et al.</em> <d-cite key="implicit_diffusion"></d-cite> and our own work <d-cite key="adjoint_deis"></d-cite>, we instead propose an <em>elegant</em> solution tailored for the face morphing problem.</p> <blockquote> <p>We don’t actually care about the intermediate latents \(\bfx_T^{(ab)}, \bfz_{ab}\) just the output \(\bfx_0^{(ab)}\)</p> </blockquote> <p>With this insight we instead propose a greedy strategy that optimizes each step of the ODE solver \(\Phi\) w.r.t. to the identity loss. We propose a new family of DiM algorithms called <em>Greedy-DiM</em> which leverages this greedy strategy to generate optimal morphs.</p> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left">DiM</th> <th style="text-align: left">Fast-DiM</th> <th style="text-align: left">Morph-PIPE</th> <th style="text-align: left">Greedy-DiM</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">ODE Solver</td> <td style="text-align: left">DDIM</td> <td style="text-align: left">DPM++ 2M</td> <td style="text-align: left">DDIM</td> <td style="text-align: left">DDIM</td> </tr> <tr> <td style="text-align: left">Number of sampling steps</td> <td style="text-align: left">100</td> <td style="text-align: left">50</td> <td style="text-align: left">2100</td> <td style="text-align: left">20</td> </tr> <tr> <td style="text-align: left">Heuristic function</td> <td style="text-align: left">✘</td> <td style="text-align: left">✘</td> <td style="text-align: left">\(\mathcal{L}_{ID}^*\)</td> <td style="text-align: left">\(\mathcal{L}_{ID}^*\)</td> </tr> <tr> <td style="text-align: left">Search strategy</td> <td style="text-align: left">✘</td> <td style="text-align: left">✘</td> <td style="text-align: left">Brute-force search</td> <td style="text-align: left">Greedy optimization</td> </tr> <tr> <td style="text-align: left">Search space</td> <td style="text-align: left">✘</td> <td style="text-align: left">✘</td> <td style="text-align: left">Set of 21 morphs</td> <td style="text-align: left">\(\X\)</td> </tr> <tr> <td style="text-align: left">Probability the search space contains the optimal solution</td> <td style="text-align: left">✘</td> <td style="text-align: left">✘</td> <td style="text-align: left">0</td> <td style="text-align: left">1</td> </tr> </tbody> </table> <div class="caption"> High level overview of all current DiM algorithms. </div> <p>To further motivate Greedy-DiM we highlight recent work by Zhang <em>et al.</em> <d-cite key="morph_pipe"></d-cite> who also explored the problem of identity-guided generation with DiMs. They proposed Morph-PIPE a simple extension upon our DiM algorithm by incorporating identity information and succeeds upon improving upon vanilla DiM. The approach can be summarized as</p> <ol> <li>Find latent representations \(\bfx_T^{(a)},\bfx_T^{(b)},\bfz_a,\bfz_b\).</li> <li>Create a set of \(N = 21\) blend parameters \(\{\gamma_n\}_{n=1}^N \subseteq [0, 1]\).</li> <li>Generate \(N\) morphs with latents \(\mathrm{slerp}(\bfx_T^{(a)},\bfx_T^{(b)};\gamma_n)\) and \(\mathrm{lerp}(\bfz_a, \bfz_b; \gamma_n)\).</li> <li>Select the best morph w.r.t. the identity loss \(\mathcal{L}_{ID}^*\)<d-footnote> The identity loss was initially proposed by Zhang <i>et al.</i> <d-cite key="mipgan"></d-cite> and was slightly modified by <d-cite key="morph_pipe"></d-cite> defined as the sum of two sub-losses: $$\mathcal{L}_{ID} = d(v_{ab}, v_a) + d(v_{ab}, v_b)\qquad \mathcal{L}_{diff} = \big|d(v_{ab}, v_a) - d(v_{ab}, v_b))\big |$$ with $$\mathcal{L}_{ID}^* = \mathcal{L}_{ID} + \mathcal{L}_{diff}\label{eq:loss_id}$$ where $v_a = F(\mathbf{x}_0^{(a)}), v_b = F(\mathbf{x}_0^{(b)}), v_{ab} = F(\mathbf{x}_0^{(ab)})$, and $F: \mathcal{X} \to V$ is an FR system which embeds images into a vector space $V$ which is equipped with a measure of distance, $d$, <i>e.g.</i> cosine distance.</d-footnote>.</li> </ol> <p>While Morph-PIPE does outperform DiM it, however, does have a few notable drawbacks.</p> <ol> <li>The approach is very computationally expensive requiring the user to fully generate a set of \(N = 21\) morphs.</li> <li>The probability that Morph-PIPE actually finds the optimal morph is 0, even as \(N \to \infty\). More on this later.</li> </ol> <p>In contrast our Greedy-DiM algorithm addresses both of these issues. First, by greedily optimizing a neighborhood around the predicted noise at each step of the ODE solver we reduce <strong>significantly</strong> reduce the number of calls to the U-Net while simultaneously expanding the size of the search space.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/greedy_dim_star-480.webp 480w,/assets/img/dim/greedy_dim_star-800.webp 800w,/assets/img/dim/greedy_dim_star-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/greedy_dim_star.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Overview of a single step of the Greedy-DiM algorithm. Additions compared to vanilla DiM highlighted in green. </div> <p>Remember that for VP type SDEs a sample at time \(t\) can be expressed as \(\bfx_t = \alpha_t\bfx_0 + \sigma_t\boldsymbol\epsilon_t\), this means we can rearrange the equation to solve for the denoised image \(\bfx_0\) to which we find \begin{equation} \label{eq:x-pred} \bfx_0 = \frac{\bfx_t - \sigma_t\boldsymbol\epsilon_t}{\alpha_t} \end{equation} Therefore, we recast our noise prediction from \(\boldsymbol\epsilon_\theta(\bfx_t, \bfz, t)\) into a prediction of \(\bfx_0\). It is this approximation which we then pass to the identity loss \(\mathcal{L}_{ID}^*\). We can then easily calculate \(\nabla_{\boldsymbol\epsilon} \mathcal{L}_{ID}^*\) using an automatic differentation library and preform gradient descent on \(\boldsymbol\epsilon\) to find the optimal \(\boldsymbol\epsilon\) w.r.t. the identity loss. We outline the Greedy-DiM algorithm with the following PyTorch pseudo code.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="n">ode_solver</span><span class="p">,</span> <span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.002</span><span class="p">,</span> <span class="n">T</span><span class="o">=</span><span class="mf">80.</span><span class="p">,</span> <span class="n">n_encode</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span> <span class="n">n_sample</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_opt_steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">opt_kwargs</span><span class="o">=</span><span class="p">{}):</span>
    <span class="sh">"""</span><span class="s">
    Greedy-DiM algorithm.

    Args:
        model (nn.Module): Noise prediction U-Net (or x-prediction / v-prediction).
        encoder (nn.Module): Encoder network.
        diff_eq (function): RHS of Probabilty Flow ODE.
        ode_solver (function): Numerical ODE solver, must be first-order!
        x_a (torch.Tensor): Image of identity a.
        x_b (torch.Tensor): Image of identity b.
        loss_fn (func): Loss function to guide generation.
        eps (float): Starting timstep. Defaults to 0.002. For numeric stability.
        T (float): Terminal timestep. Defaults to 80.
        n_encode (int): Number of encoding steps. Defaults to 250.
        n_sample (int): Number of sampling steps. Defaults to 100.
        n_opt_steps (int): Number of optimization steps per timestep of the ODE solver. Defaults to 50.
        opt_kwargs (dict): Dictionary of optimizer arguments. Defaults to {}.

    Returns:
        x_morph (torch.Tensor): The morphed image.
    </span><span class="sh">"""</span>

    <span class="c1"># Create latents
</span>    <span class="n">z_a</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">x_a</span><span class="p">)</span>
    <span class="n">z_b</span> <span class="o">=</span> <span class="nf">encoder</span><span class="p">(</span><span class="n">x_b</span><span class="p">)</span>
    
    <span class="c1"># Encode images into noise
</span>    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">n_encode</span><span class="p">)</span>
    <span class="n">xs</span> <span class="o">=</span> <span class="nf">ode_solver</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">torch</span><span class="p">.</span><span class="nf">cat</span><span class="p">((</span><span class="n">z_a</span><span class="p">,</span> <span class="n">z_b</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">)</span>
    <span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span> <span class="o">=</span> <span class="n">xs</span><span class="p">.</span><span class="nf">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Morph representations
</span>    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">lerp</span><span class="p">(</span><span class="n">z_a</span><span class="p">,</span> <span class="n">z_b</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">xt</span> <span class="o">=</span> <span class="nf">slerp</span><span class="p">(</span><span class="n">x_a</span><span class="p">,</span> <span class="n">x_b</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>  <span class="c1"># assumes slerp is defined somewhere
</span>
    <span class="c1"># Generate morph
</span>    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">eps</span><span class="p">,</span> <span class="n">n_sample</span><span class="p">)</span> 
    
    <span class="c1"># Perform Greedy Optimization
</span>    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="n">eps</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">t</span><span class="p">)</span>

        <span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">clone</span><span class="p">().</span><span class="nf">requires_grad</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">RAdam</span><span class="p">([</span><span class="n">eps</span><span class="p">],</span> <span class="o">**</span><span class="n">opt_kwargs</span><span class="p">)</span>

        <span class="n">x0_pred</span> <span class="o">=</span> <span class="nf">convert_eps_to_x0</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">.</span><span class="nf">detach</span><span class="p">())</span>  <span class="c1"># assumes Eq. (13) is implemented somewhere
</span>        <span class="n">best_loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">x0_pred</span><span class="p">)</span>
        <span class="n">best_eps</span> <span class="o">=</span> <span class="n">eps</span>

        <span class="c1"># Gradient descent on epsilon to find epsilon*
</span>        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_opt_steps</span><span class="p">):</span>
            <span class="n">opt</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>

            <span class="n">x0_pred</span> <span class="o">=</span> <span class="nf">convert_eps_to_x0</span><span class="p">(</span><span class="n">eps</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">xt</span><span class="p">.</span><span class="nf">detach</span><span class="p">())</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">x0_pred</span><span class="p">)</span>

            <span class="n">do_update</span> <span class="o">=</span> <span class="p">(</span><span class="n">loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">).</span><span class="nf">float</span><span class="p">()</span>  <span class="c1"># handles batches of morphs
</span>            <span class="n">best_loss</span> <span class="o">=</span> <span class="n">do_update</span> <span class="o">*</span> <span class="n">loss</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">do_update</span><span class="p">)</span> <span class="o">*</span> <span class="n">best_loss</span>
            <span class="n">best_eps</span> <span class="o">=</span> <span class="n">do_update</span><span class="p">[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">eps</span> <span class="o">+</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">do_update</span><span class="p">)[:,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="bp">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">best_eps</span>

            <span class="n">loss</span><span class="p">.</span><span class="nf">mean</span><span class="p">().</span><span class="nf">backward</span><span class="p">()</span>
            <span class="n">opt</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>

        <span class="n">eps</span> <span class="o">=</span> <span class="n">best_eps</span>

        <span class="c1"># Use the approximated epsilon* to take the next step of the ode solver
</span>        <span class="n">xt</span> <span class="o">=</span> <span class="nf">ode_solver</span><span class="p">(</span><span class="n">xt</span><span class="p">,</span> <span class="n">z</span><span class="p">,</span> <span class="n">diff_eq</span><span class="p">,</span> <span class="p">[</span><span class="n">t</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]])</span>
            
    <span class="k">return</span> <span class="n">xt</span>
</code></pre></div></div> <p>This simple greedy strategy results in <strong>massive</strong> improvements over DiM in both visual fidelity and morphing performance. The performance of Greedy-DiM is <strong>unreasonably effective</strong> fooling the studied FR systems a <strong>100%</strong> of the time.</p> <table> <thead> <tr> <th style="text-align: left">Morphing Attack</th> <th style="text-align: right">NFE (↓)</th> <th style="text-align: right">AdaFace (↑)</th> <th style="text-align: right">ArcFace (↑)</th> <th style="text-align: right">ElasticFace (↑)</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">FaceMorpher <d-cite key="syn-mad22"></d-cite></td> <td style="text-align: right">-</td> <td style="text-align: right">89.78</td> <td style="text-align: right">87.73</td> <td style="text-align: right">89.57</td> </tr> <tr> <td style="text-align: left">OpenCV <d-cite key="syn-mad22"></d-cite></td> <td style="text-align: right">-</td> <td style="text-align: right">94.48</td> <td style="text-align: right">92.43</td> <td style="text-align: right">94.27</td> </tr> <tr> <td style="text-align: left">MIPGAN-I <d-cite key="mipgan"></d-cite></td> <td style="text-align: right">-</td> <td style="text-align: right">72.19</td> <td style="text-align: right">77.51</td> <td style="text-align: right">66.46</td> </tr> <tr> <td style="text-align: left">MIPGAN-II <d-cite key="mipgan"></d-cite></td> <td style="text-align: right">-</td> <td style="text-align: right">70.55</td> <td style="text-align: right">72.19</td> <td style="text-align: right">65.24</td> </tr> <tr> <td style="text-align: left">DiM <d-cite key="blasingame_dim"></d-cite></td> <td style="text-align: right">350</td> <td style="text-align: right">92.23</td> <td style="text-align: right">90.18</td> <td style="text-align: right">93.05</td> </tr> <tr> <td style="text-align: left">Fast-DiM <d-cite key="fast_dim"></d-cite></td> <td style="text-align: right">300</td> <td style="text-align: right">92.02</td> <td style="text-align: right">90.18</td> <td style="text-align: right">93.05</td> </tr> <tr> <td style="text-align: left">Morph-PIPE <d-cite key="morph_pipe"></d-cite></td> <td style="text-align: right">2350</td> <td style="text-align: right">95.91</td> <td style="text-align: right">92.84</td> <td style="text-align: right">95.3</td> </tr> <tr> <td style="text-align: left">Greedy-DiM <d-cite key="greedy_dim"></d-cite></td> <td style="text-align: right">270</td> <td style="text-align: right"><strong>100</strong></td> <td style="text-align: right"><strong>100</strong></td> <td style="text-align: right"><strong>100</strong></td> </tr> </tbody> </table> <div class="caption"> Vulnerability of different of FR systems across different morphing attacks on the SYN-MAD 20222 dataset. False Match Rate (FMR) is set at 0.1% for all FR systems. Higher is better. </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/066_03-480.webp 480w,/assets/img/dim/frll/bona_fide/066_03-800.webp 800w,/assets/img/dim/frll/bona_fide/066_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/066_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>a</i></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/dim_a/066_087-480.webp 480w,/assets/img/dim/frll/dim_a/066_087-800.webp 800w,/assets/img/dim/frll/dim_a/066_087-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/dim_a/066_087.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">DiM <d-cite key="blasingame_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/greedy_dim/066_087-480.webp 480w,/assets/img/dim/frll/greedy_dim/066_087-800.webp 800w,/assets/img/dim/frll/greedy_dim/066_087-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/greedy_dim/066_087.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Greedy-DiM <d-cite key="greedy_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/morph_pipe/066_087-480.webp 480w,/assets/img/dim/frll/morph_pipe/066_087-800.webp 800w,/assets/img/dim/frll/morph_pipe/066_087-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/morph_pipe/066_087.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Morph-PIPE <d-cite key="morph_pipe"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/087_03-480.webp 480w,/assets/img/dim/frll/bona_fide/087_03-800.webp 800w,/assets/img/dim/frll/bona_fide/087_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/087_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>b</i></div> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/096_03-480.webp 480w,/assets/img/dim/frll/bona_fide/096_03-800.webp 800w,/assets/img/dim/frll/bona_fide/096_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/096_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>a</i></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/dim_a/096_137-480.webp 480w,/assets/img/dim/frll/dim_a/096_137-800.webp 800w,/assets/img/dim/frll/dim_a/096_137-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/dim_a/096_137.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">DiM <d-cite key="blasingame_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/greedy_dim/096_137-480.webp 480w,/assets/img/dim/frll/greedy_dim/096_137-800.webp 800w,/assets/img/dim/frll/greedy_dim/096_137-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/greedy_dim/096_137.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Greedy-DiM <d-cite key="greedy_dim"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/morph_pipe/096_137-480.webp 480w,/assets/img/dim/frll/morph_pipe/096_137-800.webp 800w,/assets/img/dim/frll/morph_pipe/096_137-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/morph_pipe/096_137.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Morph-PIPE <d-cite key="morph_pipe"></d-cite></div> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/frll/bona_fide/137_03-480.webp 480w,/assets/img/dim/frll/bona_fide/137_03-800.webp 800w,/assets/img/dim/frll/bona_fide/137_03-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/frll/bona_fide/137_03.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption">Face <i>b</i></div> </div> </div> <div class="caption"> Visual comparison of DiM methods. Notice the prominent red and blue saturation artefacts present in DiM and Morph-PIPE. These are absent in Greedy-DiM. </div> <p>Given the unreasonably strong empirical performance a natural question is to ask why Greedy-DiM performs so well. First, this greedy strategy is globally optimal (Theorem 3.1 <d-cite key="greedy_dim"></d-cite>). This means that at every timestep the locally optimal choice is globally optimal. Because of Equation \eqref{eq:x-pred} it follows that for any two points along the <em>same</em> solution trajectory \(\bfx_s, \bfx_t\) with \(s, t \in [0, T]\) and using a first-order solver for the <em>Probability Flow</em> ODE it follows that \(\boldsymbol\epsilon_s = \boldsymbol\epsilon_t\), i.e., the have the same realization of noise<d-footnote>This is only true for diffusion models using the <i>Probability Flow</i> ODE formulation. It is more complicated to ensure this for diffusion SDEs, the math of which is beyond the scope of this post.</d-footnote> Hence, at any time \(t\), the \(\boldsymbol\epsilon_t\) which minimizes the identity loss is globally optimal. The second justification for the <em>unreasonable</em> performance of Greedy-DiM lies in the structure of its search space.</p> <h3 id="the-search-space-of-greedy-dim-is-well-posed">The search space of Greedy-DiM is well-posed</h3> <p>The search space of Greedy-DiM is well-posed, meaning the probability the search space contains the optimal solution is 1. Formally, let \(\pr\) be probability measure on compact subset \(\X\) which denotes the distribution of the optimal face morph. For technical reasons we also assume \(\pr\) is absolutely continuous<d-footnote> A measure $\mu$ on measurable space $(\mathcal{X}, \Sigma)$ is said to be absolutely continuous w.r.t. $\nu$ iff $$(\forall A \in \Sigma) \quad \nu(A) = 0 \implies \mu(A) = 0$$ </d-footnote> w.r.t. the \(n\)-dimensional Lebesgue measure \(\lambda^n\) on \(\X\). The probability the optimal face morph lies on some set \(A \subseteq \X\) is denoted as \(\pr(A)\). Then let \(\mathcal{S}_P\) denote the search space of Morph-PIPE and let \(\mathcal{S}^*\) of Greedy-DiM. With some measure theory it is simple to prove that \(\pr(\mathcal{S}_P) = 0\) and \(\pr(\mathcal{S}^*) = 1\) (Theorem 3.2 <d-cite key="greedy_dim"></d-cite>).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/dim/search_space-480.webp 480w,/assets/img/dim/search_space-800.webp 800w,/assets/img/dim/search_space-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/dim/search_space.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> Illustration of the search space of different DiM algorithms on $\mathbb{R}^2$. The purple denotes Morph-PIPE while green denotes the search space of Greedy-DiM. </div> <p>Intuitively, the \(N = 21\) countably finite number of morphs that Morph-PIPE explores is infinitesimally small compared to the whole search space which is compact subset of Euclidean space.</p> <blockquote> <p>The search space of Greedy-DiM allows it to find the optimal morph, while Morph-PIPE’s forbids this</p> </blockquote> <p>Due to this ability of Greedy-DiM to better explore the space of morphs we can find the optimal morph. This combined with globally optimal substructure of the identity-guided DiM problem gives a reasonable explanation for why Greedy-DiM fooled the studied FR systems <strong>100%</strong> of the time.</p> <p>Note, the reason the numerical ODE solver \(\Phi\) must be first-order is that our greedy strategy breaks the guarantees needed for to accurately estimate the \(n\)-th order derivatives used in high-order solvers.</p> <h2 id="concluding-remarks">Concluding Remarks</h2> <p>This blog post gives a detailed introduction to DiM. I develop the motivation for DiM, and it’s successors Fast-DiM and Greedy-DiM, through a principled analysis of the face morphing problem. I was then able to demonstrate that this new family of morphing attacks pose a serious threat to FR systems and represent a significant advance in face morphing attacks. This post is a compilation of several papers we have published in the last few years. Please visit them if you are interested in more details.</p> <ul> <li><a href="https://arxiv.org/abs/2404.06025">Zander W. Blasingame and Chen Liu. <em>Greedy-DiM: Greedy Algorithms for Unreasonably Effective Face Morphs</em>. IJCB 2024</a></li> <li><a href="https://arxiv.org/abs/2301.04218">Zander W. Blasingame and Chen Liu. <em>Leveraging Diffusion for Strong and High Quality Face Morphing Attacks</em>. IEEE TBIOM 2024.</a></li> <li><a href="https://arxiv.org/abs/2310.09484">Zander W. Blasingame and Chen Liu. <em>Fast-DiM: Towards Fast Diffusion Morphs</em>. IEEE Security &amp; Privacy 2024.</a></li> <li><a href="https://arxiv.org/abs/2404.06559">Richard E. Neddo, Zander W. Blasingame, and Chen Liu. <em>The Impact of Print-and-Scan in Heterogeneous Morph Evaluation Scenarios</em>. IJCB 2024</a></li> </ul> <p>For more reading on more <em>efficiently</em> estimating the gradients of diffusion models please check out our recent paper.</p> <ul> <li><a href="https://openreview.net/forum?id=fAlcxvrOEX">Zander W. Blasingame and Chen Liu. <em>AdjointDEIS: Efficient Gradients for Diffusion Models</em>. NeurIPS 2024.</a></li> </ul> <p>Interestingly, our work on Greedy-DiM bares some similarity to recent work done by Yu <em>et al.</em> <d-cite key="yu2023freedom"></d-cite> as they also end up doing a one-shot gradient estimation via \(\bfx_0\)-prediction; however, they develop their approach from the prospective of energy guidance.</p> <p>It is my belief that the insights gained here are not only relevant to face morphing, but also to other downstream task with diffusion models. <em>E.g.,</em> template inversion <d-cite key="template_inversion_sebastien"></d-cite>, guided generation <d-cite key="yu2023freedom,doodl"></d-cite>, adversarial attacks <d-cite key="chen2023diffusion"></d-cite>, and even other modalities like audio.</p>]]></content><author><name>Zander W. Blasingame</name></author><category term="diffusion"/><category term="DiM"/><category term="face-morphing"/><category term="numerical-methods"/><category term="ODEs"/><category term="SDEs"/><category term="greedy-algorithms"/><summary type="html"><![CDATA[This blog introduces a new family of face morphing attacks known as Difusion Morphs (DiM). DiMs are a novel method for constructing morphed faces which exploit the iterative nature of diffusion models to construct face morphs which are more effective and more realistic in appearance. DiMs achieve state-of-the-art morphing performance and visual fidelity, far surpassing previous methods. In this blog post I will detail the intution, basic concepts, and applications of DiMs.]]></summary></entry></feed>